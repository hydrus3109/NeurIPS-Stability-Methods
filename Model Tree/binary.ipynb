{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a04d3c44-2a48-4e9f-88c8-8287f47bc1f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T17:36:17.290910Z",
     "iopub.status.busy": "2023-07-11T17:36:17.290204Z",
     "iopub.status.idle": "2023-07-11T17:36:18.536775Z",
     "shell.execute_reply": "2023-07-11T17:36:18.535878Z",
     "shell.execute_reply.started": "2023-07-11T17:36:17.290879Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms   \n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import RandomRotation\n",
    "from torchvision.transforms import Pad\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from numpy.linalg import norm\n",
    "from torch.cuda.random import device_count\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms \n",
    "import torchvision \n",
    "import math\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ca7bc5-e7bd-4cb8-859f-45ddb198ff15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T17:36:28.287116Z",
     "iopub.status.busy": "2023-07-11T17:36:28.286688Z",
     "iopub.status.idle": "2023-07-11T17:36:31.572938Z",
     "shell.execute_reply": "2023-07-11T17:36:31.572275Z",
     "shell.execute_reply.started": "2023-07-11T17:36:28.287086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.random import device_count\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms \n",
    "import torchvision \n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "transform1 = transforms.Compose(\n",
    "    [    \n",
    "    transforms.RandomCrop(32, 4),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=12),\n",
    "    transforms.ColorJitter(0.3, 0.3, 0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4, 0.4822, 0.4465), (0.247, 0.243, 0.261)),   \n",
    "    ])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./', train=True,download=True,transform = transform1)\n",
    "indices = list(range(0, 46000,1))\n",
    "trainset1 = torch.utils.data.Subset(trainset, indices)\n",
    "modelloader = torch.utils.data.DataLoader(trainset1, shuffle=True, num_workers=2, batch_size = 5000)\n",
    "validset = torchvision.datasets.CIFAR10(root='./', train=True,download=True, transform = transform) \n",
    "valid = list(range(46000, 50000,1))\n",
    "validset1 = torch.utils.data.Subset(validset, valid)\n",
    "validloader = torch.utils.data.DataLoader(validset1, shuffle=True, num_workers=2,batch_size = 100)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train = False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, shuffle=True, num_workers=2, batch_size = 1)\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a95b9b-a99d-469d-bd23-ac5d082e4524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T17:36:42.102826Z",
     "iopub.status.busy": "2023-07-11T17:36:42.102568Z",
     "iopub.status.idle": "2023-07-11T17:36:42.106489Z",
     "shell.execute_reply": "2023-07-11T17:36:42.105911Z",
     "shell.execute_reply.started": "2023-07-11T17:36:42.102807Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c8a208f-7b7c-43a0-bf9c-a83c88a143a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T17:36:44.511811Z",
     "iopub.status.busy": "2023-07-11T17:36:44.511058Z",
     "iopub.status.idle": "2023-07-11T17:36:44.525050Z",
     "shell.execute_reply": "2023-07-11T17:36:44.524164Z",
     "shell.execute_reply.started": "2023-07-11T17:36:44.511785Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                \"\"\"\n",
    "                For CIFAR10 ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                             F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "      #  self.dropout = nn.Dropout(0.2)\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "     #   out = self.dropout(out)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def resnetlowest(classes):\n",
    "    return ResNet(BasicBlock, [1, 1, 1], classes)\n",
    "def resnetlower(classes):\n",
    "    return ResNet(BasicBlock, [2, 2, 2], classes)\n",
    "def resnet20(classes):\n",
    "    return ResNet(BasicBlock, [3, 3, 3], classes)\n",
    "def resnet32(classes):\n",
    "    return ResNet(BasicBlock, [5, 5, 5], classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "348deceb-e2c1-4a95-acf7-eb360e64fc2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-01T17:41:29.116356Z",
     "iopub.status.busy": "2023-07-01T17:41:29.116039Z",
     "iopub.status.idle": "2023-07-01T17:41:30.759353Z",
     "shell.execute_reply": "2023-07-01T17:41:30.758411Z",
     "shell.execute_reply.started": "2023-07-01T17:41:29.116331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141562\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 =nn.Conv2d(64, 128, 3)\n",
    "        self.fc1 = nn.Linear(128 * 2 * 2, 84)\n",
    "        self.fc2 = nn.Linear(84,60)\n",
    "        self.fc3 = nn.Linear(60, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "      #  print(x.size())\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n",
    "#model.load_state_dict(torch.load(\"binaryCNN\"))\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "print(get_n_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af3acb-e2d7-4f07-b6fa-ea47020c470f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-27T03:08:31.933185Z",
     "iopub.status.idle": "2023-06-27T03:08:31.933508Z",
     "shell.execute_reply": "2023-06-27T03:08:31.933367Z",
     "shell.execute_reply.started": "2023-06-27T03:08:31.933349Z"
    }
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x) + x\n",
    "\n",
    "\n",
    "def ConvMixer(dim, depth, kernel_size=5, patch_size=2, n_classes=10):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size),\n",
    "        nn.GELU(),\n",
    "        nn.BatchNorm2d(dim),\n",
    "        *[nn.Sequential(\n",
    "                Residual(nn.Sequential(\n",
    "                    nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "                    nn.GELU(),\n",
    "                    nn.BatchNorm2d(dim)\n",
    "                )),\n",
    "                nn.Conv2d(dim, dim, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.BatchNorm2d(dim)\n",
    "        ) for i in range(depth)],\n",
    "        nn.AdaptiveAvgPool2d((1,1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(dim, n_classes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47500d8b-29ad-4f98-ba80-90a296f954a2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-27T03:08:31.934564Z",
     "iopub.status.idle": "2023-06-27T03:08:31.934896Z",
     "shell.execute_reply": "2023-06-27T03:08:31.934736Z",
     "shell.execute_reply.started": "2023-06-27T03:08:31.934719Z"
    }
   },
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7226a77f-c12a-4c2e-a90f-c11334a9d14e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T16:06:48.615288Z",
     "iopub.status.busy": "2023-07-11T16:06:48.614898Z",
     "iopub.status.idle": "2023-07-11T16:06:48.641623Z",
     "shell.execute_reply": "2023-07-11T16:06:48.640405Z",
     "shell.execute_reply.started": "2023-07-11T16:06:48.615259Z"
    }
   },
   "outputs": [],
   "source": [
    "def layer1transform(array,size):\n",
    "    newarr = array.detach().clone()\n",
    "    for i in range(size):\n",
    "        if array[i] <= 5:\n",
    "            newarr[i] = 0\n",
    "        else: \n",
    "            newarr[i] = 1\n",
    "    return newarr\n",
    "def optimizedtransform(array,size):\n",
    "    newarr = array.detach().clone()\n",
    "    for i in range(size):\n",
    "        if array[i] < 2 or array[i] > 7:\n",
    "            newarr[i] = 0\n",
    "        else: \n",
    "            newarr[i] = 1\n",
    "   # print(newarr.size())\n",
    "    return newarr\n",
    "def vehicletransform(data, array,size):\n",
    "    newdata = torch.Tensor()\n",
    "    newdata = newdata.to(device)\n",
    "    newarr = torch.Tensor()\n",
    "    newarr = newarr.to(device)\n",
    "    count=0\n",
    "    for i in range(size):\n",
    "        ztensor = torch.zeros(1)\n",
    "        ztensor = ztensor.to(device)\n",
    "        otensor = torch.Tensor([1])\n",
    "        otensor = otensor.to(device)\n",
    "        if array[i] < 2 or array[i] >= 8:\n",
    "            newdata = torch.cat((newdata,data[i].unsqueeze(0)),dim=0)       \n",
    "            count = count+1\n",
    "            if array[i] == 0:\n",
    "                newarr = torch.cat((newarr,ztensor),dim=0)\n",
    "            elif array[i] == 1:\n",
    "                newarr = torch.cat((newarr,otensor),dim=0)\n",
    "            elif array[i] == 8: \n",
    "                newarr = torch.cat((newarr,ztensor),dim=0)\n",
    "            elif array[i] == 9: \n",
    "                newarr = torch.cat((newarr,otensor),dim=0)\n",
    "               # print(newarr)\n",
    "    return newdata, newarr, count\n",
    "def airshiptransform(data, array,size):\n",
    "    newdata = torch.Tensor()\n",
    "    newdata = newdata.to(device)\n",
    "    newarr = torch.Tensor()\n",
    "    newarr = newarr.to(device)\n",
    "    count=0\n",
    "    for i in range(size):\n",
    "        ztensor = torch.zeros(1)\n",
    "        ztensor = ztensor.to(device)\n",
    "        otensor = torch.Tensor([1])\n",
    "        otensor = otensor.to(device)\n",
    "        if array[i] == 0 or array[i] == 8:\n",
    "            newdata = torch.cat((newdata,data[i].unsqueeze(0)),dim=0)       \n",
    "            count = count+1\n",
    "            if array[i] == 0:\n",
    "                newarr = torch.cat((newarr,ztensor),dim=0)\n",
    "            elif array[i] == 8: \n",
    "                newarr = torch.cat((newarr,otensor),dim=0)\n",
    "               # print(newarr)\n",
    "    return newdata, newarr, count\n",
    "def cartrucktransform(data, array,size):\n",
    "    newdata = torch.Tensor()\n",
    "    newdata = newdata.to(device)\n",
    "    newarr = torch.Tensor()\n",
    "    newarr = newarr.to(device)\n",
    "    count=0\n",
    "    for i in range(size):\n",
    "        ztensor = torch.zeros(1)\n",
    "        ztensor = ztensor.to(device)\n",
    "        otensor = torch.Tensor([1])\n",
    "        otensor = otensor.to(device)\n",
    "        if array[i] == 1 or array[i] == 9:\n",
    "            newdata = torch.cat((newdata,data[i].unsqueeze(0)),dim=0)       \n",
    "            count = count+1\n",
    "           # print(array[i])\n",
    "            if array[i] == 1:\n",
    "                newarr = torch.cat((newarr,ztensor),dim=0)\n",
    "            elif array[i] == 9: \n",
    "                newarr = torch.cat((newarr,otensor),dim=0)\n",
    "               # print(newarr)\n",
    "    return newdata, newarr, count\n",
    "def animaltransform(data, array,size):\n",
    "    newdata = torch.Tensor()\n",
    "    newdata = newdata.to(device)\n",
    "    newarr = torch.Tensor()\n",
    "    newarr = newarr.to(device)\n",
    "    count=0\n",
    "    for i in range(size):\n",
    "        ztensor = torch.zeros(1)\n",
    "        ztensor = ztensor.to(device)\n",
    "        otensor = torch.Tensor([1])\n",
    "        otensor = otensor.to(device)\n",
    "        ttensor = torch.Tensor([2])\n",
    "        ttensor = ttensor.to(device)\n",
    "        if array[i] >=2 and array[i] < 8:\n",
    "            newdata = torch.cat((newdata,data[i].unsqueeze(0)),dim=0)       \n",
    "            count = count+1\n",
    "            if array[i] == 2:\n",
    "                newarr = torch.cat((newarr,ztensor),dim=0)\n",
    "            elif array[i] == 3:\n",
    "                newarr = torch.cat((newarr,otensor),dim=0)\n",
    "            elif array[i] == 4: \n",
    "                newarr = torch.cat((newarr,ttensor),dim=0)\n",
    "            elif array[i] == 5: \n",
    "                newarr = torch.cat((newarr,otensor),dim=0)\n",
    "            elif array[i] == 6: \n",
    "                newarr = torch.cat((newarr,ztensor),dim=0)\n",
    "            elif array[i] == 7: \n",
    "                newarr = torch.cat((newarr,ttensor),dim=0)\n",
    "    #print(newdata.size())\n",
    "   # print(newarr.size())\n",
    "    return newdata, newarr, count\n",
    "def catdogtransform(data, array,size):\n",
    "    newdata = torch.Tensor()\n",
    "    newdata = newdata.to(device)\n",
    "    newarr = torch.Tensor()\n",
    "    newarr = newarr.to(device)\n",
    "    count=0\n",
    "    for i in range(size):\n",
    "        ztensor = torch.zeros(1)\n",
    "        ztensor = ztensor.to(device)\n",
    "        otensor = torch.Tensor([1])\n",
    "        otensor = otensor.to(device)\n",
    "        if array[i] == 3 or array[i] ==5:\n",
    "            newdata = torch.cat((newdata,data[i].unsqueeze(0)),dim=0)       \n",
    "            count = count+1\n",
    "            if array[i] == 3:\n",
    "                newarr = torch.cat((newarr,ztensor),dim=0)\n",
    "            elif array[i] == 5: \n",
    "                newarr = torch.cat((newarr,otensor),dim=0)\n",
    "               # print(newarr)\n",
    "    return newdata, newarr, count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3deed3-a9ba-4244-b2ae-949f4606c3a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T17:37:36.477885Z",
     "iopub.status.busy": "2023-07-11T17:37:36.477154Z",
     "iopub.status.idle": "2023-07-11T17:37:36.487058Z",
     "shell.execute_reply": "2023-07-11T17:37:36.486299Z",
     "shell.execute_reply.started": "2023-07-11T17:37:36.477859Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def vehicletransform(data, array,size):\n",
    "    newdata = torch.Tensor()\n",
    "    newdata = newdata.to(device)\n",
    "    newarr = torch.Tensor()\n",
    "    newarr = newarr.to(device)\n",
    "    count=0\n",
    "    for i in range(size):\n",
    "        ztensor = torch.zeros(1)\n",
    "        ztensor = ztensor.to(device)\n",
    "        otensor = torch.Tensor([1])\n",
    "        otensor = otensor.to(device)\n",
    "        ttensor = torch.Tensor([2])\n",
    "        ttensor = ttensor.to(device)\n",
    "        thtensor = torch.tensor([3])\n",
    "        thtensor = thtensor.to(device)\n",
    "        if array[i] < 2 or array[i] >= 8:\n",
    "            newdata = torch.cat((newdata,data[i].unsqueeze(0)),dim=0)       \n",
    "            count = count+1\n",
    "            if array[i] == 0:\n",
    "                newarr = torch.cat((newarr,ztensor),dim=0)\n",
    "            elif array[i] == 1:\n",
    "                newarr = torch.cat((newarr,otensor),dim=0)\n",
    "            elif array[i] == 8: \n",
    "                newarr = torch.cat((newarr,ttensor),dim=0)\n",
    "            elif array[i] == 9: \n",
    "                newarr = torch.cat((newarr,thtensor),dim=0)\n",
    "               # print(newarr)\n",
    "    return newdata, newarr, count\n",
    "    \n",
    "def animaltransform(data, array,size):\n",
    "    newdata = torch.Tensor()\n",
    "    newdata = newdata.to(device)\n",
    "    newarr = torch.Tensor()\n",
    "    newarr = newarr.to(device)\n",
    "    count=0\n",
    "    for i in range(size):\n",
    "        ztensor = torch.zeros(1)\n",
    "        ztensor = ztensor.to(device)\n",
    "        otensor = torch.Tensor([1])\n",
    "        otensor = otensor.to(device)\n",
    "        ttensor = torch.Tensor([2])\n",
    "        ttensor = ttensor.to(device)\n",
    "        thtensor = torch.Tensor([3])\n",
    "        thtensor = thtensor.to(device)\n",
    "        fotensor = torch.Tensor([4])\n",
    "        fotensor = fotensor.to(device)\n",
    "        ftensor = torch.Tensor([5])\n",
    "        ftensor = ftensor.to(device)\n",
    "        if array[i] >=2 and array[i] < 8:\n",
    "            newdata = torch.cat((newdata,data[i].unsqueeze(0)),dim=0)       \n",
    "            count = count+1\n",
    "            if array[i] == 2:\n",
    "                newarr = torch.cat((newarr,ztensor),dim=0)\n",
    "            elif array[i] == 3:\n",
    "                newarr = torch.cat((newarr,otensor),dim=0)\n",
    "            elif array[i] == 4: \n",
    "                newarr = torch.cat((newarr,ttensor),dim=0)\n",
    "            elif array[i] == 5: \n",
    "                newarr = torch.cat((newarr,thtensor),dim=0)\n",
    "            elif array[i] == 6: \n",
    "                newarr = torch.cat((newarr,fotensor),dim=0)\n",
    "            elif array[i] == 7: \n",
    "                newarr = torch.cat((newarr,ftensor),dim=0)\n",
    "    #print(newdata.size())\n",
    "   # print(newarr.size())\n",
    "    return newdata, newarr, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b247a606-d88d-4900-8490-d433b0e7ff1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T17:41:53.387140Z",
     "iopub.status.busy": "2023-07-11T17:41:53.385991Z",
     "iopub.status.idle": "2023-07-11T17:41:53.408707Z",
     "shell.execute_reply": "2023-07-11T17:41:53.407720Z",
     "shell.execute_reply.started": "2023-07-11T17:41:53.387124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269462\n"
     ]
    }
   ],
   "source": [
    "#model = resnetlowest(2)\n",
    "model = resnet20(6)\n",
    "#model = LeNet5(2)\n",
    "#model = ConvMixer(256, 8, patch_size=2, kernel_size=5, n_classes=2)\n",
    "model.to(device)\n",
    "#model.load_state_dict(torch.load(\"animal5000batch\"))\n",
    "#model.to(device)\n",
    "\n",
    "print(get_n_params(model))\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "# = optim.SGD(model.parameters(), lr=0.01, weight_decay = 0.001, momentum = 0.9)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.02, weight_decay=0.01)\n",
    "#optim.Adam(model.parameters(), lr = 0.001)\n",
    "#optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad0ea29-9ca4-4da1-a573-e424c262ff03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T15:32:00.936564Z",
     "iopub.status.busy": "2023-07-02T15:32:00.935796Z",
     "iopub.status.idle": "2023-07-02T15:32:01.709314Z",
     "shell.execute_reply": "2023-07-02T15:32:01.708219Z",
     "shell.execute_reply.started": "2023-07-02T15:32:00.936526Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizedtransform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m modelloader:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# move tensors to GPU if CUDA is available\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 24\u001b[0m     newtarget \u001b[38;5;241m=\u001b[39m \u001b[43moptimizedtransform\u001b[49m(target,\u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#print(newtarget)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# clear the gradients of all optimized variables\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizedtransform' is not defined"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "train_losslist = []\n",
    "train_losslist1 = []\n",
    "#number of epochs to train the model\n",
    "n_epochs = [*range(300)] # you may increase this number to train a final model\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in n_epochs:\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    train_loss1 = 0.0\n",
    "    valid_loss = 0.0   \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    #model1.train()\n",
    "    class_correct1 = list(0. for i in range(10))\n",
    "    class_total1 = list(0. for i in range(10))\n",
    "    for data, target in modelloader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        newtarget = optimizedtransform(target,500)\n",
    "        #print(newtarget)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        #optimizer1.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        #output1 = model1(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, newtarget)\n",
    "        #loss.backward()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "       # optimizer.step()\n",
    "        #optimizer1.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        #train_loss1 += loss1.item()*data.size(0)\n",
    "        _, pred = torch.max(output, 1)  \n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(newtarget.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(500):\n",
    "            label = newtarget.data[i]\n",
    "            class_correct1[label] += correct[i].item()\n",
    "            class_total1[label] += 1\n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    for data, target in validloader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        #if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        newtarget = optimizedtransform(target,100)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, newtarget)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)  \n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(newtarget.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(100):\n",
    "            label = newtarget.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "            # calculate average losses\n",
    "    valid_loss = valid_loss/len(validloader.dataset)\n",
    "    train_loss = train_loss/len(modelloader.dataset)\n",
    "    train_losslist.append(train_loss)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    print('Training Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct1) / np.sum(class_total1),\n",
    "    np.sum(class_correct1), np.sum(class_total1)))\n",
    "    print('Validation Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n",
    "        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2baaafbf-e3f5-47f9-91df-ce0c7a085e1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T17:41:56.158670Z",
     "iopub.status.busy": "2023-07-11T17:41:56.157914Z",
     "iopub.status.idle": "2023-07-11T19:24:27.811298Z",
     "shell.execute_reply": "2023-07-11T19:24:27.810713Z",
     "shell.execute_reply.started": "2023-07-11T17:41:56.158647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 2.615837 \tValidation Loss: 6844.218896\n",
      "Training Accuracy (Overall): 16% (4697/27632)\n",
      "Validation Accuracy (Overall): 16% (388/2368)\n",
      "Epoch: 1 \tTraining Loss: 1.817883 \tValidation Loss: 17.174475\n",
      "Training Accuracy (Overall): 19% (5328/27632)\n",
      "Validation Accuracy (Overall): 16% (384/2368)\n",
      "Epoch: 2 \tTraining Loss: 1.773839 \tValidation Loss: 1.839972\n",
      "Training Accuracy (Overall): 22% (6122/27632)\n",
      "Validation Accuracy (Overall): 23% (563/2368)\n",
      "Epoch: 3 \tTraining Loss: 1.740445 \tValidation Loss: 1.740845\n",
      "Training Accuracy (Overall): 24% (6849/27632)\n",
      "Validation Accuracy (Overall): 23% (566/2368)\n",
      "Epoch: 4 \tTraining Loss: 1.718048 \tValidation Loss: 1.678947\n",
      "Training Accuracy (Overall): 26% (7190/27632)\n",
      "Validation Accuracy (Overall): 28% (670/2368)\n",
      "Epoch: 5 \tTraining Loss: 1.689913 \tValidation Loss: 1.678343\n",
      "Training Accuracy (Overall): 28% (7858/27632)\n",
      "Validation Accuracy (Overall): 28% (678/2368)\n",
      "Epoch: 6 \tTraining Loss: 1.662700 \tValidation Loss: 1.610586\n",
      "Training Accuracy (Overall): 30% (8465/27632)\n",
      "Validation Accuracy (Overall): 32% (780/2368)\n",
      "Epoch: 7 \tTraining Loss: 1.631443 \tValidation Loss: 1.650391\n",
      "Training Accuracy (Overall): 32% (8880/27632)\n",
      "Validation Accuracy (Overall): 32% (774/2368)\n",
      "Epoch: 8 \tTraining Loss: 1.600533 \tValidation Loss: 1.634172\n",
      "Training Accuracy (Overall): 34% (9482/27632)\n",
      "Validation Accuracy (Overall): 35% (834/2368)\n",
      "Epoch: 9 \tTraining Loss: 1.576372 \tValidation Loss: 1.499593\n",
      "Training Accuracy (Overall): 35% (9825/27632)\n",
      "Validation Accuracy (Overall): 41% (982/2368)\n",
      "Epoch: 10 \tTraining Loss: 1.538469 \tValidation Loss: 1.459604\n",
      "Training Accuracy (Overall): 37% (10394/27632)\n",
      "Validation Accuracy (Overall): 42% (1001/2368)\n",
      "Epoch: 11 \tTraining Loss: 1.504613 \tValidation Loss: 1.500165\n",
      "Training Accuracy (Overall): 39% (10817/27632)\n",
      "Validation Accuracy (Overall): 40% (967/2368)\n",
      "Epoch: 12 \tTraining Loss: 1.474762 \tValidation Loss: 1.424201\n",
      "Training Accuracy (Overall): 40% (11206/27632)\n",
      "Validation Accuracy (Overall): 42% (1008/2368)\n",
      "Epoch: 13 \tTraining Loss: 1.445408 \tValidation Loss: 1.567771\n",
      "Training Accuracy (Overall): 42% (11609/27632)\n",
      "Validation Accuracy (Overall): 39% (931/2368)\n",
      "Epoch: 14 \tTraining Loss: 1.434818 \tValidation Loss: 1.482970\n",
      "Training Accuracy (Overall): 42% (11752/27632)\n",
      "Validation Accuracy (Overall): 41% (989/2368)\n",
      "Epoch: 15 \tTraining Loss: 1.403141 \tValidation Loss: 1.489457\n",
      "Training Accuracy (Overall): 43% (12128/27632)\n",
      "Validation Accuracy (Overall): 43% (1028/2368)\n",
      "Epoch: 16 \tTraining Loss: 1.375184 \tValidation Loss: 1.244465\n",
      "Training Accuracy (Overall): 45% (12457/27632)\n",
      "Validation Accuracy (Overall): 51% (1218/2368)\n",
      "Epoch: 17 \tTraining Loss: 1.344416 \tValidation Loss: 1.331075\n",
      "Training Accuracy (Overall): 46% (12925/27632)\n",
      "Validation Accuracy (Overall): 47% (1131/2368)\n",
      "Epoch: 18 \tTraining Loss: 1.333063 \tValidation Loss: 1.253018\n",
      "Training Accuracy (Overall): 47% (13080/27632)\n",
      "Validation Accuracy (Overall): 51% (1214/2368)\n",
      "Epoch: 19 \tTraining Loss: 1.324265 \tValidation Loss: 1.358660\n",
      "Training Accuracy (Overall): 47% (13118/27632)\n",
      "Validation Accuracy (Overall): 47% (1135/2368)\n",
      "Epoch: 20 \tTraining Loss: 1.283013 \tValidation Loss: 1.235424\n",
      "Training Accuracy (Overall): 49% (13670/27632)\n",
      "Validation Accuracy (Overall): 53% (1269/2368)\n",
      "Epoch: 21 \tTraining Loss: 1.266726 \tValidation Loss: 1.254259\n",
      "Training Accuracy (Overall): 50% (13920/27632)\n",
      "Validation Accuracy (Overall): 51% (1218/2368)\n",
      "Epoch: 22 \tTraining Loss: 1.266334 \tValidation Loss: 1.211705\n",
      "Training Accuracy (Overall): 50% (13862/27632)\n",
      "Validation Accuracy (Overall): 53% (1268/2368)\n",
      "Epoch: 23 \tTraining Loss: 1.239440 \tValidation Loss: 1.260689\n",
      "Training Accuracy (Overall): 51% (14221/27632)\n",
      "Validation Accuracy (Overall): 52% (1234/2368)\n",
      "Epoch: 24 \tTraining Loss: 1.224356 \tValidation Loss: 1.402597\n",
      "Training Accuracy (Overall): 52% (14388/27632)\n",
      "Validation Accuracy (Overall): 47% (1133/2368)\n",
      "Epoch: 25 \tTraining Loss: 1.215530 \tValidation Loss: 1.200875\n",
      "Training Accuracy (Overall): 52% (14574/27632)\n",
      "Validation Accuracy (Overall): 54% (1286/2368)\n",
      "Epoch: 26 \tTraining Loss: 1.189879 \tValidation Loss: 1.269880\n",
      "Training Accuracy (Overall): 53% (14799/27632)\n",
      "Validation Accuracy (Overall): 52% (1249/2368)\n",
      "Epoch: 27 \tTraining Loss: 1.166843 \tValidation Loss: 1.222549\n",
      "Training Accuracy (Overall): 54% (15139/27632)\n",
      "Validation Accuracy (Overall): 54% (1286/2368)\n",
      "Epoch: 28 \tTraining Loss: 1.158681 \tValidation Loss: 1.072676\n",
      "Training Accuracy (Overall): 54% (15192/27632)\n",
      "Validation Accuracy (Overall): 59% (1408/2368)\n",
      "Epoch: 29 \tTraining Loss: 1.135064 \tValidation Loss: 1.121303\n",
      "Training Accuracy (Overall): 56% (15541/27632)\n",
      "Validation Accuracy (Overall): 58% (1397/2368)\n",
      "Epoch: 30 \tTraining Loss: 1.118789 \tValidation Loss: 1.235645\n",
      "Training Accuracy (Overall): 57% (15791/27632)\n",
      "Validation Accuracy (Overall): 56% (1333/2368)\n",
      "Epoch: 31 \tTraining Loss: 1.107130 \tValidation Loss: 1.060533\n",
      "Training Accuracy (Overall): 57% (15962/27632)\n",
      "Validation Accuracy (Overall): 60% (1422/2368)\n",
      "Epoch: 32 \tTraining Loss: 1.092707 \tValidation Loss: 1.020399\n",
      "Training Accuracy (Overall): 58% (16032/27632)\n",
      "Validation Accuracy (Overall): 61% (1456/2368)\n",
      "Epoch: 33 \tTraining Loss: 1.066852 \tValidation Loss: 1.069298\n",
      "Training Accuracy (Overall): 59% (16428/27632)\n",
      "Validation Accuracy (Overall): 61% (1453/2368)\n",
      "Epoch: 34 \tTraining Loss: 1.062785 \tValidation Loss: 1.405207\n",
      "Training Accuracy (Overall): 59% (16472/27632)\n",
      "Validation Accuracy (Overall): 50% (1185/2368)\n",
      "Epoch: 35 \tTraining Loss: 1.037804 \tValidation Loss: 1.140077\n",
      "Training Accuracy (Overall): 60% (16783/27632)\n",
      "Validation Accuracy (Overall): 57% (1368/2368)\n",
      "Epoch: 36 \tTraining Loss: 1.017460 \tValidation Loss: 1.020730\n",
      "Training Accuracy (Overall): 61% (17037/27632)\n",
      "Validation Accuracy (Overall): 63% (1497/2368)\n",
      "Epoch: 37 \tTraining Loss: 0.992728 \tValidation Loss: 0.949932\n",
      "Training Accuracy (Overall): 62% (17187/27632)\n",
      "Validation Accuracy (Overall): 64% (1516/2368)\n",
      "Epoch: 38 \tTraining Loss: 0.977118 \tValidation Loss: 1.063081\n",
      "Training Accuracy (Overall): 63% (17538/27632)\n",
      "Validation Accuracy (Overall): 62% (1483/2368)\n",
      "Epoch: 39 \tTraining Loss: 0.968005 \tValidation Loss: 1.127092\n",
      "Training Accuracy (Overall): 63% (17548/27632)\n",
      "Validation Accuracy (Overall): 59% (1419/2368)\n",
      "Epoch: 40 \tTraining Loss: 0.963080 \tValidation Loss: 0.984695\n",
      "Training Accuracy (Overall): 63% (17620/27632)\n",
      "Validation Accuracy (Overall): 63% (1509/2368)\n",
      "Epoch: 41 \tTraining Loss: 0.930273 \tValidation Loss: 1.258599\n",
      "Training Accuracy (Overall): 65% (18011/27632)\n",
      "Validation Accuracy (Overall): 53% (1275/2368)\n",
      "Epoch: 42 \tTraining Loss: 0.922823 \tValidation Loss: 0.904053\n",
      "Training Accuracy (Overall): 65% (18062/27632)\n",
      "Validation Accuracy (Overall): 67% (1593/2368)\n",
      "Epoch: 43 \tTraining Loss: 0.893653 \tValidation Loss: 1.098827\n",
      "Training Accuracy (Overall): 66% (18385/27632)\n",
      "Validation Accuracy (Overall): 62% (1482/2368)\n",
      "Epoch: 44 \tTraining Loss: 0.878773 \tValidation Loss: 1.083559\n",
      "Training Accuracy (Overall): 67% (18608/27632)\n",
      "Validation Accuracy (Overall): 61% (1459/2368)\n",
      "Epoch: 45 \tTraining Loss: 0.875532 \tValidation Loss: 0.917541\n",
      "Training Accuracy (Overall): 67% (18709/27632)\n",
      "Validation Accuracy (Overall): 68% (1616/2368)\n",
      "Epoch: 46 \tTraining Loss: 0.852783 \tValidation Loss: 1.028708\n",
      "Training Accuracy (Overall): 68% (18903/27632)\n",
      "Validation Accuracy (Overall): 64% (1529/2368)\n",
      "Epoch: 47 \tTraining Loss: 0.827106 \tValidation Loss: 0.852353\n",
      "Training Accuracy (Overall): 69% (19280/27632)\n",
      "Validation Accuracy (Overall): 70% (1669/2368)\n",
      "Epoch: 48 \tTraining Loss: 0.813590 \tValidation Loss: 0.870758\n",
      "Training Accuracy (Overall): 69% (19298/27632)\n",
      "Validation Accuracy (Overall): 70% (1669/2368)\n",
      "Epoch: 49 \tTraining Loss: 0.800183 \tValidation Loss: 0.869244\n",
      "Training Accuracy (Overall): 70% (19477/27632)\n",
      "Validation Accuracy (Overall): 68% (1631/2368)\n",
      "Epoch: 50 \tTraining Loss: 0.797647 \tValidation Loss: 0.773455\n",
      "Training Accuracy (Overall): 70% (19473/27632)\n",
      "Validation Accuracy (Overall): 72% (1714/2368)\n",
      "Epoch: 51 \tTraining Loss: 0.780096 \tValidation Loss: 0.828730\n",
      "Training Accuracy (Overall): 71% (19730/27632)\n",
      "Validation Accuracy (Overall): 71% (1688/2368)\n",
      "Epoch: 52 \tTraining Loss: 0.782570 \tValidation Loss: 0.887988\n",
      "Training Accuracy (Overall): 71% (19632/27632)\n",
      "Validation Accuracy (Overall): 69% (1640/2368)\n",
      "Epoch: 53 \tTraining Loss: 0.765654 \tValidation Loss: 0.848906\n",
      "Training Accuracy (Overall): 71% (19758/27632)\n",
      "Validation Accuracy (Overall): 71% (1688/2368)\n",
      "Epoch: 54 \tTraining Loss: 0.755731 \tValidation Loss: 0.849565\n",
      "Training Accuracy (Overall): 72% (19981/27632)\n",
      "Validation Accuracy (Overall): 69% (1646/2368)\n",
      "Epoch: 55 \tTraining Loss: 0.752181 \tValidation Loss: 0.895694\n",
      "Training Accuracy (Overall): 72% (20004/27632)\n",
      "Validation Accuracy (Overall): 70% (1665/2368)\n",
      "Epoch: 56 \tTraining Loss: 0.742538 \tValidation Loss: 0.822094\n",
      "Training Accuracy (Overall): 72% (20047/27632)\n",
      "Validation Accuracy (Overall): 70% (1676/2368)\n",
      "Epoch: 57 \tTraining Loss: 0.712061 \tValidation Loss: 0.688697\n",
      "Training Accuracy (Overall): 73% (20423/27632)\n",
      "Validation Accuracy (Overall): 75% (1797/2368)\n",
      "Epoch: 58 \tTraining Loss: 0.703827 \tValidation Loss: 0.763323\n",
      "Training Accuracy (Overall): 74% (20497/27632)\n",
      "Validation Accuracy (Overall): 73% (1736/2368)\n",
      "Epoch: 59 \tTraining Loss: 0.703799 \tValidation Loss: 0.723693\n",
      "Training Accuracy (Overall): 74% (20571/27632)\n",
      "Validation Accuracy (Overall): 74% (1774/2368)\n",
      "Epoch: 60 \tTraining Loss: 0.686052 \tValidation Loss: 0.743799\n",
      "Training Accuracy (Overall): 74% (20684/27632)\n",
      "Validation Accuracy (Overall): 74% (1764/2368)\n",
      "Epoch: 61 \tTraining Loss: 0.690772 \tValidation Loss: 0.746466\n",
      "Training Accuracy (Overall): 74% (20654/27632)\n",
      "Validation Accuracy (Overall): 74% (1756/2368)\n",
      "Epoch: 62 \tTraining Loss: 0.682682 \tValidation Loss: 0.671889\n",
      "Training Accuracy (Overall): 75% (20747/27632)\n",
      "Validation Accuracy (Overall): 76% (1810/2368)\n",
      "Epoch: 63 \tTraining Loss: 0.664748 \tValidation Loss: 0.691649\n",
      "Training Accuracy (Overall): 75% (20892/27632)\n",
      "Validation Accuracy (Overall): 75% (1796/2368)\n",
      "Epoch: 64 \tTraining Loss: 0.665662 \tValidation Loss: 0.628460\n",
      "Training Accuracy (Overall): 75% (20917/27632)\n",
      "Validation Accuracy (Overall): 77% (1842/2368)\n",
      "Epoch: 65 \tTraining Loss: 0.657048 \tValidation Loss: 0.718566\n",
      "Training Accuracy (Overall): 76% (21037/27632)\n",
      "Validation Accuracy (Overall): 76% (1809/2368)\n",
      "Epoch: 66 \tTraining Loss: 0.650133 \tValidation Loss: 0.730312\n",
      "Training Accuracy (Overall): 76% (21027/27632)\n",
      "Validation Accuracy (Overall): 74% (1763/2368)\n",
      "Epoch: 67 \tTraining Loss: 0.640437 \tValidation Loss: 0.798305\n",
      "Training Accuracy (Overall): 76% (21188/27632)\n",
      "Validation Accuracy (Overall): 72% (1719/2368)\n",
      "Epoch: 68 \tTraining Loss: 0.632264 \tValidation Loss: 0.806439\n",
      "Training Accuracy (Overall): 77% (21377/27632)\n",
      "Validation Accuracy (Overall): 74% (1765/2368)\n",
      "Epoch: 69 \tTraining Loss: 0.623617 \tValidation Loss: 0.652657\n",
      "Training Accuracy (Overall): 77% (21384/27632)\n",
      "Validation Accuracy (Overall): 77% (1826/2368)\n",
      "Epoch: 70 \tTraining Loss: 0.622027 \tValidation Loss: 0.597156\n",
      "Training Accuracy (Overall): 77% (21392/27632)\n",
      "Validation Accuracy (Overall): 79% (1871/2368)\n",
      "Epoch: 71 \tTraining Loss: 0.604643 \tValidation Loss: 0.608106\n",
      "Training Accuracy (Overall): 77% (21535/27632)\n",
      "Validation Accuracy (Overall): 80% (1896/2368)\n",
      "Epoch: 72 \tTraining Loss: 0.607141 \tValidation Loss: 0.568669\n",
      "Training Accuracy (Overall): 77% (21538/27632)\n",
      "Validation Accuracy (Overall): 79% (1890/2368)\n",
      "Epoch: 73 \tTraining Loss: 0.611665 \tValidation Loss: 0.639672\n",
      "Training Accuracy (Overall): 77% (21515/27632)\n",
      "Validation Accuracy (Overall): 77% (1841/2368)\n",
      "Epoch: 74 \tTraining Loss: 0.601353 \tValidation Loss: 0.601914\n",
      "Training Accuracy (Overall): 78% (21570/27632)\n",
      "Validation Accuracy (Overall): 79% (1888/2368)\n",
      "Epoch: 75 \tTraining Loss: 0.597718 \tValidation Loss: 0.582896\n",
      "Training Accuracy (Overall): 78% (21637/27632)\n",
      "Validation Accuracy (Overall): 79% (1887/2368)\n",
      "Epoch: 76 \tTraining Loss: 0.589005 \tValidation Loss: 0.612251\n",
      "Training Accuracy (Overall): 78% (21680/27632)\n",
      "Validation Accuracy (Overall): 79% (1871/2368)\n",
      "Epoch: 77 \tTraining Loss: 0.584724 \tValidation Loss: 0.709167\n",
      "Training Accuracy (Overall): 78% (21747/27632)\n",
      "Validation Accuracy (Overall): 77% (1835/2368)\n",
      "Epoch: 78 \tTraining Loss: 0.579980 \tValidation Loss: 0.792950\n",
      "Training Accuracy (Overall): 78% (21822/27632)\n",
      "Validation Accuracy (Overall): 73% (1731/2368)\n",
      "Epoch: 79 \tTraining Loss: 0.581798 \tValidation Loss: 0.536179\n",
      "Training Accuracy (Overall): 78% (21798/27632)\n",
      "Validation Accuracy (Overall): 81% (1938/2368)\n",
      "Epoch: 80 \tTraining Loss: 0.569354 \tValidation Loss: 0.766816\n",
      "Training Accuracy (Overall): 79% (21950/27632)\n",
      "Validation Accuracy (Overall): 74% (1768/2368)\n",
      "Epoch: 81 \tTraining Loss: 0.564148 \tValidation Loss: 0.568353\n",
      "Training Accuracy (Overall): 79% (21900/27632)\n",
      "Validation Accuracy (Overall): 79% (1890/2368)\n",
      "Epoch: 82 \tTraining Loss: 0.558327 \tValidation Loss: 0.604221\n",
      "Training Accuracy (Overall): 79% (22018/27632)\n",
      "Validation Accuracy (Overall): 79% (1888/2368)\n",
      "Epoch: 83 \tTraining Loss: 0.560682 \tValidation Loss: 0.971622\n",
      "Training Accuracy (Overall): 79% (21995/27632)\n",
      "Validation Accuracy (Overall): 70% (1658/2368)\n",
      "Epoch: 84 \tTraining Loss: 0.553324 \tValidation Loss: 0.567500\n",
      "Training Accuracy (Overall): 79% (22067/27632)\n",
      "Validation Accuracy (Overall): 80% (1913/2368)\n",
      "Epoch: 85 \tTraining Loss: 0.546606 \tValidation Loss: 0.498383\n",
      "Training Accuracy (Overall): 80% (22254/27632)\n",
      "Validation Accuracy (Overall): 82% (1959/2368)\n",
      "Epoch: 86 \tTraining Loss: 0.543575 \tValidation Loss: 0.805128\n",
      "Training Accuracy (Overall): 80% (22215/27632)\n",
      "Validation Accuracy (Overall): 75% (1786/2368)\n",
      "Epoch: 87 \tTraining Loss: 0.533088 \tValidation Loss: 0.628451\n",
      "Training Accuracy (Overall): 80% (22316/27632)\n",
      "Validation Accuracy (Overall): 80% (1903/2368)\n",
      "Epoch: 88 \tTraining Loss: 0.521934 \tValidation Loss: 0.546511\n",
      "Training Accuracy (Overall): 81% (22488/27632)\n",
      "Validation Accuracy (Overall): 81% (1920/2368)\n",
      "Epoch: 89 \tTraining Loss: 0.531959 \tValidation Loss: 0.564392\n",
      "Training Accuracy (Overall): 80% (22350/27632)\n",
      "Validation Accuracy (Overall): 81% (1921/2368)\n",
      "Epoch: 90 \tTraining Loss: 0.528596 \tValidation Loss: 0.700541\n",
      "Training Accuracy (Overall): 80% (22368/27632)\n",
      "Validation Accuracy (Overall): 78% (1848/2368)\n",
      "Epoch: 91 \tTraining Loss: 0.516377 \tValidation Loss: 0.538008\n",
      "Training Accuracy (Overall): 81% (22453/27632)\n",
      "Validation Accuracy (Overall): 82% (1943/2368)\n",
      "Epoch: 92 \tTraining Loss: 0.507665 \tValidation Loss: 0.542654\n",
      "Training Accuracy (Overall): 81% (22591/27632)\n",
      "Validation Accuracy (Overall): 81% (1932/2368)\n",
      "Epoch: 93 \tTraining Loss: 0.512052 \tValidation Loss: 0.487711\n",
      "Training Accuracy (Overall): 81% (22518/27632)\n",
      "Validation Accuracy (Overall): 83% (1978/2368)\n",
      "Epoch: 94 \tTraining Loss: 0.512691 \tValidation Loss: 0.548294\n",
      "Training Accuracy (Overall): 81% (22543/27632)\n",
      "Validation Accuracy (Overall): 82% (1943/2368)\n",
      "Epoch: 95 \tTraining Loss: 0.510479 \tValidation Loss: 0.559782\n",
      "Training Accuracy (Overall): 81% (22501/27632)\n",
      "Validation Accuracy (Overall): 81% (1938/2368)\n",
      "Epoch: 96 \tTraining Loss: 0.499992 \tValidation Loss: 0.539642\n",
      "Training Accuracy (Overall): 81% (22582/27632)\n",
      "Validation Accuracy (Overall): 81% (1939/2368)\n",
      "Epoch: 97 \tTraining Loss: 0.498353 \tValidation Loss: 0.484608\n",
      "Training Accuracy (Overall): 81% (22611/27632)\n",
      "Validation Accuracy (Overall): 83% (1982/2368)\n",
      "Epoch: 98 \tTraining Loss: 0.494715 \tValidation Loss: 0.585909\n",
      "Training Accuracy (Overall): 82% (22664/27632)\n",
      "Validation Accuracy (Overall): 80% (1912/2368)\n",
      "Epoch: 99 \tTraining Loss: 0.495592 \tValidation Loss: 0.485944\n",
      "Training Accuracy (Overall): 82% (22677/27632)\n",
      "Validation Accuracy (Overall): 83% (1977/2368)\n",
      "Epoch: 100 \tTraining Loss: 0.493291 \tValidation Loss: 0.497764\n",
      "Training Accuracy (Overall): 81% (22640/27632)\n",
      "Validation Accuracy (Overall): 82% (1958/2368)\n",
      "Epoch: 101 \tTraining Loss: 0.483589 \tValidation Loss: 0.608700\n",
      "Training Accuracy (Overall): 82% (22825/27632)\n",
      "Validation Accuracy (Overall): 80% (1918/2368)\n",
      "Epoch: 102 \tTraining Loss: 0.476751 \tValidation Loss: 0.584595\n",
      "Training Accuracy (Overall): 82% (22871/27632)\n",
      "Validation Accuracy (Overall): 80% (1905/2368)\n",
      "Epoch: 103 \tTraining Loss: 0.479725 \tValidation Loss: 0.647535\n",
      "Training Accuracy (Overall): 82% (22811/27632)\n",
      "Validation Accuracy (Overall): 80% (1899/2368)\n",
      "Epoch: 104 \tTraining Loss: 0.469846 \tValidation Loss: 0.627485\n",
      "Training Accuracy (Overall): 82% (22925/27632)\n",
      "Validation Accuracy (Overall): 79% (1892/2368)\n",
      "Epoch: 105 \tTraining Loss: 0.464238 \tValidation Loss: 0.580028\n",
      "Training Accuracy (Overall): 83% (22970/27632)\n",
      "Validation Accuracy (Overall): 81% (1926/2368)\n",
      "Epoch: 106 \tTraining Loss: 0.475433 \tValidation Loss: 0.582254\n",
      "Training Accuracy (Overall): 82% (22812/27632)\n",
      "Validation Accuracy (Overall): 81% (1941/2368)\n",
      "Epoch: 107 \tTraining Loss: 0.472024 \tValidation Loss: 0.592746\n",
      "Training Accuracy (Overall): 82% (22910/27632)\n",
      "Validation Accuracy (Overall): 79% (1885/2368)\n",
      "Epoch: 108 \tTraining Loss: 0.468393 \tValidation Loss: 0.513184\n",
      "Training Accuracy (Overall): 83% (22955/27632)\n",
      "Validation Accuracy (Overall): 81% (1935/2368)\n",
      "Epoch: 109 \tTraining Loss: 0.452224 \tValidation Loss: 0.443692\n",
      "Training Accuracy (Overall): 83% (23017/27632)\n",
      "Validation Accuracy (Overall): 85% (2031/2368)\n",
      "Epoch: 110 \tTraining Loss: 0.451939 \tValidation Loss: 0.602034\n",
      "Training Accuracy (Overall): 83% (23130/27632)\n",
      "Validation Accuracy (Overall): 80% (1902/2368)\n",
      "Epoch: 111 \tTraining Loss: 0.449458 \tValidation Loss: 0.584226\n",
      "Training Accuracy (Overall): 83% (23194/27632)\n",
      "Validation Accuracy (Overall): 81% (1940/2368)\n",
      "Epoch: 112 \tTraining Loss: 0.445487 \tValidation Loss: 0.558011\n",
      "Training Accuracy (Overall): 84% (23215/27632)\n",
      "Validation Accuracy (Overall): 82% (1944/2368)\n",
      "Epoch: 113 \tTraining Loss: 0.442142 \tValidation Loss: 0.488072\n",
      "Training Accuracy (Overall): 84% (23314/27632)\n",
      "Validation Accuracy (Overall): 84% (2002/2368)\n",
      "Epoch: 114 \tTraining Loss: 0.445255 \tValidation Loss: 0.588410\n",
      "Training Accuracy (Overall): 83% (23178/27632)\n",
      "Validation Accuracy (Overall): 81% (1931/2368)\n",
      "Epoch: 115 \tTraining Loss: 0.445035 \tValidation Loss: 0.460790\n",
      "Training Accuracy (Overall): 83% (23155/27632)\n",
      "Validation Accuracy (Overall): 84% (2002/2368)\n",
      "Epoch: 116 \tTraining Loss: 0.436023 \tValidation Loss: 0.642025\n",
      "Training Accuracy (Overall): 84% (23250/27632)\n",
      "Validation Accuracy (Overall): 80% (1904/2368)\n",
      "Epoch: 117 \tTraining Loss: 0.438343 \tValidation Loss: 0.488839\n",
      "Training Accuracy (Overall): 84% (23287/27632)\n",
      "Validation Accuracy (Overall): 83% (1981/2368)\n",
      "Epoch: 118 \tTraining Loss: 0.437849 \tValidation Loss: 0.471337\n",
      "Training Accuracy (Overall): 84% (23313/27632)\n",
      "Validation Accuracy (Overall): 84% (1993/2368)\n",
      "Epoch: 119 \tTraining Loss: 0.430867 \tValidation Loss: 0.484985\n",
      "Training Accuracy (Overall): 84% (23358/27632)\n",
      "Validation Accuracy (Overall): 83% (1980/2368)\n",
      "Epoch: 120 \tTraining Loss: 0.431082 \tValidation Loss: 0.528308\n",
      "Training Accuracy (Overall): 84% (23389/27632)\n",
      "Validation Accuracy (Overall): 83% (1969/2368)\n",
      "Epoch: 121 \tTraining Loss: 0.431886 \tValidation Loss: 0.461212\n",
      "Training Accuracy (Overall): 84% (23317/27632)\n",
      "Validation Accuracy (Overall): 84% (1992/2368)\n",
      "Epoch: 122 \tTraining Loss: 0.423276 \tValidation Loss: 0.489603\n",
      "Training Accuracy (Overall): 84% (23476/27632)\n",
      "Validation Accuracy (Overall): 83% (1971/2368)\n",
      "Epoch: 123 \tTraining Loss: 0.419171 \tValidation Loss: 0.502208\n",
      "Training Accuracy (Overall): 84% (23487/27632)\n",
      "Validation Accuracy (Overall): 83% (1968/2368)\n",
      "Epoch: 124 \tTraining Loss: 0.422072 \tValidation Loss: 0.667989\n",
      "Training Accuracy (Overall): 84% (23424/27632)\n",
      "Validation Accuracy (Overall): 80% (1896/2368)\n",
      "Epoch: 125 \tTraining Loss: 0.424231 \tValidation Loss: 0.505646\n",
      "Training Accuracy (Overall): 84% (23403/27632)\n",
      "Validation Accuracy (Overall): 84% (1991/2368)\n",
      "Epoch: 126 \tTraining Loss: 0.407389 \tValidation Loss: 0.535879\n",
      "Training Accuracy (Overall): 85% (23595/27632)\n",
      "Validation Accuracy (Overall): 83% (1986/2368)\n",
      "Epoch: 127 \tTraining Loss: 0.409884 \tValidation Loss: 0.508633\n",
      "Training Accuracy (Overall): 85% (23585/27632)\n",
      "Validation Accuracy (Overall): 83% (1967/2368)\n",
      "Epoch: 128 \tTraining Loss: 0.412273 \tValidation Loss: 0.479350\n",
      "Training Accuracy (Overall): 85% (23552/27632)\n",
      "Validation Accuracy (Overall): 85% (2014/2368)\n",
      "Epoch: 129 \tTraining Loss: 0.409005 \tValidation Loss: 0.553527\n",
      "Training Accuracy (Overall): 85% (23546/27632)\n",
      "Validation Accuracy (Overall): 82% (1957/2368)\n",
      "Epoch: 130 \tTraining Loss: 0.412710 \tValidation Loss: 0.456038\n",
      "Training Accuracy (Overall): 84% (23480/27632)\n",
      "Validation Accuracy (Overall): 84% (2003/2368)\n",
      "Epoch: 131 \tTraining Loss: 0.396568 \tValidation Loss: 0.442889\n",
      "Training Accuracy (Overall): 85% (23719/27632)\n",
      "Validation Accuracy (Overall): 85% (2035/2368)\n",
      "Epoch: 132 \tTraining Loss: 0.399323 \tValidation Loss: 0.563543\n",
      "Training Accuracy (Overall): 85% (23661/27632)\n",
      "Validation Accuracy (Overall): 83% (1967/2368)\n",
      "Epoch: 133 \tTraining Loss: 0.397819 \tValidation Loss: 0.587935\n",
      "Training Accuracy (Overall): 85% (23653/27632)\n",
      "Validation Accuracy (Overall): 81% (1935/2368)\n",
      "Epoch: 134 \tTraining Loss: 0.395936 \tValidation Loss: 0.456619\n",
      "Training Accuracy (Overall): 85% (23638/27632)\n",
      "Validation Accuracy (Overall): 85% (2034/2368)\n",
      "Epoch: 135 \tTraining Loss: 0.395654 \tValidation Loss: 0.618513\n",
      "Training Accuracy (Overall): 85% (23710/27632)\n",
      "Validation Accuracy (Overall): 79% (1885/2368)\n",
      "Epoch: 136 \tTraining Loss: 0.397455 \tValidation Loss: 0.598313\n",
      "Training Accuracy (Overall): 85% (23670/27632)\n",
      "Validation Accuracy (Overall): 81% (1932/2368)\n",
      "Epoch: 137 \tTraining Loss: 0.386882 \tValidation Loss: 0.766056\n",
      "Training Accuracy (Overall): 86% (23782/27632)\n",
      "Validation Accuracy (Overall): 78% (1851/2368)\n",
      "Epoch: 138 \tTraining Loss: 0.393443 \tValidation Loss: 0.508491\n",
      "Training Accuracy (Overall): 85% (23750/27632)\n",
      "Validation Accuracy (Overall): 83% (1981/2368)\n",
      "Epoch: 139 \tTraining Loss: 0.388360 \tValidation Loss: 0.639122\n",
      "Training Accuracy (Overall): 85% (23719/27632)\n",
      "Validation Accuracy (Overall): 80% (1908/2368)\n",
      "Epoch: 140 \tTraining Loss: 0.382561 \tValidation Loss: 0.450704\n",
      "Training Accuracy (Overall): 86% (23793/27632)\n",
      "Validation Accuracy (Overall): 85% (2023/2368)\n",
      "Epoch: 141 \tTraining Loss: 0.391010 \tValidation Loss: 0.571303\n",
      "Training Accuracy (Overall): 86% (23765/27632)\n",
      "Validation Accuracy (Overall): 82% (1955/2368)\n",
      "Epoch: 142 \tTraining Loss: 0.390627 \tValidation Loss: 0.486244\n",
      "Training Accuracy (Overall): 85% (23759/27632)\n",
      "Validation Accuracy (Overall): 83% (1985/2368)\n",
      "Epoch: 143 \tTraining Loss: 0.389683 \tValidation Loss: 0.460434\n",
      "Training Accuracy (Overall): 86% (23774/27632)\n",
      "Validation Accuracy (Overall): 85% (2030/2368)\n",
      "Epoch: 144 \tTraining Loss: 0.379782 \tValidation Loss: 0.518800\n",
      "Training Accuracy (Overall): 86% (23815/27632)\n",
      "Validation Accuracy (Overall): 83% (1981/2368)\n",
      "Epoch: 145 \tTraining Loss: 0.383299 \tValidation Loss: 0.492162\n",
      "Training Accuracy (Overall): 86% (23833/27632)\n",
      "Validation Accuracy (Overall): 84% (2001/2368)\n",
      "Epoch: 146 \tTraining Loss: 0.379866 \tValidation Loss: 0.585938\n",
      "Training Accuracy (Overall): 86% (23837/27632)\n",
      "Validation Accuracy (Overall): 81% (1936/2368)\n",
      "Epoch: 147 \tTraining Loss: 0.373968 \tValidation Loss: 0.551799\n",
      "Training Accuracy (Overall): 86% (23909/27632)\n",
      "Validation Accuracy (Overall): 83% (1985/2368)\n",
      "Epoch: 148 \tTraining Loss: 0.384329 \tValidation Loss: 0.474919\n",
      "Training Accuracy (Overall): 86% (23811/27632)\n",
      "Validation Accuracy (Overall): 84% (1991/2368)\n",
      "Epoch: 149 \tTraining Loss: 0.372755 \tValidation Loss: 0.544602\n",
      "Training Accuracy (Overall): 86% (23952/27632)\n",
      "Validation Accuracy (Overall): 82% (1962/2368)\n",
      "Epoch: 150 \tTraining Loss: 0.383675 \tValidation Loss: 0.548541\n",
      "Training Accuracy (Overall): 86% (23766/27632)\n",
      "Validation Accuracy (Overall): 82% (1965/2368)\n",
      "Epoch: 151 \tTraining Loss: 0.382015 \tValidation Loss: 0.549267\n",
      "Training Accuracy (Overall): 86% (23802/27632)\n",
      "Validation Accuracy (Overall): 83% (1973/2368)\n",
      "Epoch: 152 \tTraining Loss: 0.366930 \tValidation Loss: 0.642917\n",
      "Training Accuracy (Overall): 86% (24013/27632)\n",
      "Validation Accuracy (Overall): 80% (1911/2368)\n",
      "Epoch: 153 \tTraining Loss: 0.359670 \tValidation Loss: 0.610091\n",
      "Training Accuracy (Overall): 86% (24036/27632)\n",
      "Validation Accuracy (Overall): 81% (1939/2368)\n",
      "Epoch: 154 \tTraining Loss: 0.365938 \tValidation Loss: 0.495451\n",
      "Training Accuracy (Overall): 86% (23970/27632)\n",
      "Validation Accuracy (Overall): 84% (2000/2368)\n",
      "Epoch: 155 \tTraining Loss: 0.362674 \tValidation Loss: 0.475645\n",
      "Training Accuracy (Overall): 86% (24027/27632)\n",
      "Validation Accuracy (Overall): 84% (2010/2368)\n",
      "Epoch: 156 \tTraining Loss: 0.356490 \tValidation Loss: 0.443192\n",
      "Training Accuracy (Overall): 87% (24103/27632)\n",
      "Validation Accuracy (Overall): 85% (2025/2368)\n",
      "Epoch: 157 \tTraining Loss: 0.356325 \tValidation Loss: 0.461405\n",
      "Training Accuracy (Overall): 87% (24051/27632)\n",
      "Validation Accuracy (Overall): 84% (2012/2368)\n",
      "Epoch: 158 \tTraining Loss: 0.358741 \tValidation Loss: 0.496519\n",
      "Training Accuracy (Overall): 87% (24092/27632)\n",
      "Validation Accuracy (Overall): 85% (2026/2368)\n",
      "Epoch: 159 \tTraining Loss: 0.366378 \tValidation Loss: 0.481152\n",
      "Training Accuracy (Overall): 87% (24042/27632)\n",
      "Validation Accuracy (Overall): 84% (2004/2368)\n",
      "Epoch: 160 \tTraining Loss: 0.362701 \tValidation Loss: 0.458317\n",
      "Training Accuracy (Overall): 86% (23985/27632)\n",
      "Validation Accuracy (Overall): 84% (2007/2368)\n",
      "Epoch: 161 \tTraining Loss: 0.359317 \tValidation Loss: 0.507851\n",
      "Training Accuracy (Overall): 87% (24088/27632)\n",
      "Validation Accuracy (Overall): 83% (1984/2368)\n",
      "Epoch: 162 \tTraining Loss: 0.354198 \tValidation Loss: 0.560940\n",
      "Training Accuracy (Overall): 87% (24062/27632)\n",
      "Validation Accuracy (Overall): 83% (1976/2368)\n",
      "Epoch: 163 \tTraining Loss: 0.348868 \tValidation Loss: 0.472950\n",
      "Training Accuracy (Overall): 87% (24209/27632)\n",
      "Validation Accuracy (Overall): 85% (2017/2368)\n",
      "Epoch: 164 \tTraining Loss: 0.350147 \tValidation Loss: 0.480613\n",
      "Training Accuracy (Overall): 87% (24105/27632)\n",
      "Validation Accuracy (Overall): 84% (2003/2368)\n",
      "Epoch: 165 \tTraining Loss: 0.347945 \tValidation Loss: 0.619777\n",
      "Training Accuracy (Overall): 87% (24117/27632)\n",
      "Validation Accuracy (Overall): 81% (1928/2368)\n",
      "Epoch: 166 \tTraining Loss: 0.344602 \tValidation Loss: 0.545440\n",
      "Training Accuracy (Overall): 87% (24179/27632)\n",
      "Validation Accuracy (Overall): 84% (1990/2368)\n",
      "Epoch: 167 \tTraining Loss: 0.350631 \tValidation Loss: 0.584443\n",
      "Training Accuracy (Overall): 87% (24175/27632)\n",
      "Validation Accuracy (Overall): 82% (1949/2368)\n",
      "Epoch: 168 \tTraining Loss: 0.345576 \tValidation Loss: 0.542789\n",
      "Training Accuracy (Overall): 87% (24239/27632)\n",
      "Validation Accuracy (Overall): 83% (1983/2368)\n",
      "Epoch: 169 \tTraining Loss: 0.336717 \tValidation Loss: 0.432875\n",
      "Training Accuracy (Overall): 87% (24270/27632)\n",
      "Validation Accuracy (Overall): 85% (2014/2368)\n",
      "Epoch: 170 \tTraining Loss: 0.348369 \tValidation Loss: 0.540659\n",
      "Training Accuracy (Overall): 87% (24189/27632)\n",
      "Validation Accuracy (Overall): 83% (1967/2368)\n",
      "Epoch: 171 \tTraining Loss: 0.353955 \tValidation Loss: 0.466223\n",
      "Training Accuracy (Overall): 87% (24094/27632)\n",
      "Validation Accuracy (Overall): 84% (2010/2368)\n",
      "Epoch: 172 \tTraining Loss: 0.340849 \tValidation Loss: 0.530389\n",
      "Training Accuracy (Overall): 87% (24223/27632)\n",
      "Validation Accuracy (Overall): 84% (1993/2368)\n",
      "Epoch: 173 \tTraining Loss: 0.340949 \tValidation Loss: 0.548491\n",
      "Training Accuracy (Overall): 87% (24297/27632)\n",
      "Validation Accuracy (Overall): 82% (1962/2368)\n",
      "Epoch: 174 \tTraining Loss: 0.337527 \tValidation Loss: 0.454345\n",
      "Training Accuracy (Overall): 87% (24293/27632)\n",
      "Validation Accuracy (Overall): 85% (2031/2368)\n",
      "Epoch: 175 \tTraining Loss: 0.342037 \tValidation Loss: 0.448113\n",
      "Training Accuracy (Overall): 87% (24189/27632)\n",
      "Validation Accuracy (Overall): 85% (2026/2368)\n",
      "Epoch: 176 \tTraining Loss: 0.342455 \tValidation Loss: 0.637560\n",
      "Training Accuracy (Overall): 87% (24178/27632)\n",
      "Validation Accuracy (Overall): 81% (1921/2368)\n",
      "Epoch: 177 \tTraining Loss: 0.337310 \tValidation Loss: 0.388437\n",
      "Training Accuracy (Overall): 87% (24237/27632)\n",
      "Validation Accuracy (Overall): 87% (2073/2368)\n",
      "Epoch: 178 \tTraining Loss: 0.344547 \tValidation Loss: 0.537661\n",
      "Training Accuracy (Overall): 87% (24226/27632)\n",
      "Validation Accuracy (Overall): 83% (1980/2368)\n",
      "Epoch: 179 \tTraining Loss: 0.337265 \tValidation Loss: 0.474249\n",
      "Training Accuracy (Overall): 87% (24255/27632)\n",
      "Validation Accuracy (Overall): 84% (2012/2368)\n",
      "Epoch: 180 \tTraining Loss: 0.329085 \tValidation Loss: 0.445966\n",
      "Training Accuracy (Overall): 88% (24412/27632)\n",
      "Validation Accuracy (Overall): 86% (2047/2368)\n",
      "Epoch: 181 \tTraining Loss: 0.323792 \tValidation Loss: 0.379604\n",
      "Training Accuracy (Overall): 88% (24415/27632)\n",
      "Validation Accuracy (Overall): 87% (2065/2368)\n",
      "Epoch: 182 \tTraining Loss: 0.324875 \tValidation Loss: 0.470107\n",
      "Training Accuracy (Overall): 88% (24395/27632)\n",
      "Validation Accuracy (Overall): 84% (2000/2368)\n",
      "Epoch: 183 \tTraining Loss: 0.333618 \tValidation Loss: 0.449879\n",
      "Training Accuracy (Overall): 87% (24312/27632)\n",
      "Validation Accuracy (Overall): 86% (2048/2368)\n",
      "Epoch: 184 \tTraining Loss: 0.321985 \tValidation Loss: 0.457346\n",
      "Training Accuracy (Overall): 88% (24430/27632)\n",
      "Validation Accuracy (Overall): 86% (2039/2368)\n",
      "Epoch: 185 \tTraining Loss: 0.316030 \tValidation Loss: 0.613559\n",
      "Training Accuracy (Overall): 88% (24475/27632)\n",
      "Validation Accuracy (Overall): 81% (1937/2368)\n",
      "Epoch: 186 \tTraining Loss: 0.314038 \tValidation Loss: 0.521301\n",
      "Training Accuracy (Overall): 88% (24466/27632)\n",
      "Validation Accuracy (Overall): 83% (1984/2368)\n",
      "Epoch: 187 \tTraining Loss: 0.331242 \tValidation Loss: 0.474960\n",
      "Training Accuracy (Overall): 87% (24255/27632)\n",
      "Validation Accuracy (Overall): 85% (2023/2368)\n",
      "Epoch: 188 \tTraining Loss: 0.335385 \tValidation Loss: 0.544937\n",
      "Training Accuracy (Overall): 87% (24262/27632)\n",
      "Validation Accuracy (Overall): 83% (1981/2368)\n",
      "Epoch: 189 \tTraining Loss: 0.321260 \tValidation Loss: 0.426158\n",
      "Training Accuracy (Overall): 88% (24406/27632)\n",
      "Validation Accuracy (Overall): 86% (2045/2368)\n",
      "Epoch: 190 \tTraining Loss: 0.322427 \tValidation Loss: 0.449566\n",
      "Training Accuracy (Overall): 88% (24379/27632)\n",
      "Validation Accuracy (Overall): 85% (2030/2368)\n",
      "Epoch: 191 \tTraining Loss: 0.317465 \tValidation Loss: 0.388943\n",
      "Training Accuracy (Overall): 88% (24465/27632)\n",
      "Validation Accuracy (Overall): 87% (2076/2368)\n",
      "Epoch: 192 \tTraining Loss: 0.320765 \tValidation Loss: 0.473650\n",
      "Training Accuracy (Overall): 88% (24438/27632)\n",
      "Validation Accuracy (Overall): 85% (2031/2368)\n",
      "Epoch: 193 \tTraining Loss: 0.314739 \tValidation Loss: 0.476348\n",
      "Training Accuracy (Overall): 88% (24549/27632)\n",
      "Validation Accuracy (Overall): 86% (2037/2368)\n",
      "Epoch: 194 \tTraining Loss: 0.316605 \tValidation Loss: 0.466785\n",
      "Training Accuracy (Overall): 88% (24530/27632)\n",
      "Validation Accuracy (Overall): 85% (2026/2368)\n",
      "Epoch: 195 \tTraining Loss: 0.306924 \tValidation Loss: 0.514620\n",
      "Training Accuracy (Overall): 88% (24583/27632)\n",
      "Validation Accuracy (Overall): 84% (1994/2368)\n",
      "Epoch: 196 \tTraining Loss: 0.313024 \tValidation Loss: 0.465618\n",
      "Training Accuracy (Overall): 88% (24523/27632)\n",
      "Validation Accuracy (Overall): 85% (2030/2368)\n",
      "Epoch: 197 \tTraining Loss: 0.313167 \tValidation Loss: 0.384537\n",
      "Training Accuracy (Overall): 88% (24499/27632)\n",
      "Validation Accuracy (Overall): 88% (2092/2368)\n",
      "Epoch: 198 \tTraining Loss: 0.317384 \tValidation Loss: 0.488760\n",
      "Training Accuracy (Overall): 88% (24471/27632)\n",
      "Validation Accuracy (Overall): 84% (1999/2368)\n",
      "Epoch: 199 \tTraining Loss: 0.317263 \tValidation Loss: 0.446448\n",
      "Training Accuracy (Overall): 88% (24468/27632)\n",
      "Validation Accuracy (Overall): 85% (2035/2368)\n",
      "Epoch: 200 \tTraining Loss: 0.313918 \tValidation Loss: 0.540916\n",
      "Training Accuracy (Overall): 88% (24463/27632)\n",
      "Validation Accuracy (Overall): 84% (2000/2368)\n",
      "Epoch: 201 \tTraining Loss: 0.321826 \tValidation Loss: 0.437873\n",
      "Training Accuracy (Overall): 88% (24449/27632)\n",
      "Validation Accuracy (Overall): 86% (2056/2368)\n",
      "Epoch: 202 \tTraining Loss: 0.310768 \tValidation Loss: 0.478142\n",
      "Training Accuracy (Overall): 88% (24585/27632)\n",
      "Validation Accuracy (Overall): 85% (2026/2368)\n",
      "Epoch: 203 \tTraining Loss: 0.313911 \tValidation Loss: 0.484762\n",
      "Training Accuracy (Overall): 88% (24516/27632)\n",
      "Validation Accuracy (Overall): 85% (2013/2368)\n",
      "Epoch: 204 \tTraining Loss: 0.314144 \tValidation Loss: 0.402303\n",
      "Training Accuracy (Overall): 88% (24524/27632)\n",
      "Validation Accuracy (Overall): 86% (2058/2368)\n",
      "Epoch: 205 \tTraining Loss: 0.309788 \tValidation Loss: 0.423606\n",
      "Training Accuracy (Overall): 88% (24518/27632)\n",
      "Validation Accuracy (Overall): 87% (2063/2368)\n",
      "Epoch: 206 \tTraining Loss: 0.306113 \tValidation Loss: 0.499076\n",
      "Training Accuracy (Overall): 89% (24642/27632)\n",
      "Validation Accuracy (Overall): 84% (1998/2368)\n",
      "Epoch: 207 \tTraining Loss: 0.317174 \tValidation Loss: 0.459900\n",
      "Training Accuracy (Overall): 88% (24488/27632)\n",
      "Validation Accuracy (Overall): 86% (2045/2368)\n",
      "Epoch: 208 \tTraining Loss: 0.321184 \tValidation Loss: 0.404419\n",
      "Training Accuracy (Overall): 88% (24406/27632)\n",
      "Validation Accuracy (Overall): 85% (2035/2368)\n",
      "Epoch: 209 \tTraining Loss: 0.315343 \tValidation Loss: 0.399703\n",
      "Training Accuracy (Overall): 88% (24520/27632)\n",
      "Validation Accuracy (Overall): 87% (2077/2368)\n",
      "Epoch: 210 \tTraining Loss: 0.323972 \tValidation Loss: 0.458746\n",
      "Training Accuracy (Overall): 88% (24399/27632)\n",
      "Validation Accuracy (Overall): 84% (2010/2368)\n",
      "Epoch: 211 \tTraining Loss: 0.301707 \tValidation Loss: 0.533612\n",
      "Training Accuracy (Overall): 89% (24653/27632)\n",
      "Validation Accuracy (Overall): 83% (1985/2368)\n",
      "Epoch: 212 \tTraining Loss: 0.309687 \tValidation Loss: 0.460797\n",
      "Training Accuracy (Overall): 88% (24556/27632)\n",
      "Validation Accuracy (Overall): 85% (2035/2368)\n",
      "Epoch: 213 \tTraining Loss: 0.306588 \tValidation Loss: 0.414064\n",
      "Training Accuracy (Overall): 88% (24551/27632)\n",
      "Validation Accuracy (Overall): 86% (2051/2368)\n",
      "Epoch: 214 \tTraining Loss: 0.300731 \tValidation Loss: 0.519066\n",
      "Training Accuracy (Overall): 89% (24623/27632)\n",
      "Validation Accuracy (Overall): 84% (2005/2368)\n",
      "Epoch: 215 \tTraining Loss: 0.313135 \tValidation Loss: 0.563910\n",
      "Training Accuracy (Overall): 88% (24528/27632)\n",
      "Validation Accuracy (Overall): 84% (1992/2368)\n",
      "Epoch: 216 \tTraining Loss: 0.303706 \tValidation Loss: 0.449972\n",
      "Training Accuracy (Overall): 89% (24625/27632)\n",
      "Validation Accuracy (Overall): 85% (2028/2368)\n",
      "Epoch: 217 \tTraining Loss: 0.305322 \tValidation Loss: 0.469236\n",
      "Training Accuracy (Overall): 88% (24589/27632)\n",
      "Validation Accuracy (Overall): 86% (2049/2368)\n",
      "Epoch: 218 \tTraining Loss: 0.301216 \tValidation Loss: 0.427077\n",
      "Training Accuracy (Overall): 89% (24670/27632)\n",
      "Validation Accuracy (Overall): 85% (2024/2368)\n",
      "Epoch: 219 \tTraining Loss: 0.304766 \tValidation Loss: 0.472753\n",
      "Training Accuracy (Overall): 89% (24632/27632)\n",
      "Validation Accuracy (Overall): 86% (2039/2368)\n",
      "Epoch: 220 \tTraining Loss: 0.297870 \tValidation Loss: 0.503204\n",
      "Training Accuracy (Overall): 89% (24672/27632)\n",
      "Validation Accuracy (Overall): 85% (2017/2368)\n",
      "Epoch: 221 \tTraining Loss: 0.302053 \tValidation Loss: 0.486781\n",
      "Training Accuracy (Overall): 89% (24651/27632)\n",
      "Validation Accuracy (Overall): 85% (2022/2368)\n",
      "Epoch: 222 \tTraining Loss: 0.301105 \tValidation Loss: 0.506880\n",
      "Training Accuracy (Overall): 89% (24662/27632)\n",
      "Validation Accuracy (Overall): 85% (2018/2368)\n",
      "Epoch: 223 \tTraining Loss: 0.309474 \tValidation Loss: 0.417029\n",
      "Training Accuracy (Overall): 88% (24571/27632)\n",
      "Validation Accuracy (Overall): 86% (2055/2368)\n",
      "Epoch: 224 \tTraining Loss: 0.298400 \tValidation Loss: 0.390489\n",
      "Training Accuracy (Overall): 89% (24617/27632)\n",
      "Validation Accuracy (Overall): 88% (2093/2368)\n",
      "Epoch: 225 \tTraining Loss: 0.296891 \tValidation Loss: 0.510850\n",
      "Training Accuracy (Overall): 89% (24659/27632)\n",
      "Validation Accuracy (Overall): 85% (2016/2368)\n",
      "Epoch: 226 \tTraining Loss: 0.289088 \tValidation Loss: 0.396589\n",
      "Training Accuracy (Overall): 89% (24787/27632)\n",
      "Validation Accuracy (Overall): 87% (2061/2368)\n",
      "Epoch: 227 \tTraining Loss: 0.284340 \tValidation Loss: 0.451626\n",
      "Training Accuracy (Overall): 89% (24738/27632)\n",
      "Validation Accuracy (Overall): 86% (2046/2368)\n",
      "Epoch: 228 \tTraining Loss: 0.289154 \tValidation Loss: 0.594494\n",
      "Training Accuracy (Overall): 89% (24824/27632)\n",
      "Validation Accuracy (Overall): 84% (1995/2368)\n",
      "Epoch: 229 \tTraining Loss: 0.285461 \tValidation Loss: 0.389088\n",
      "Training Accuracy (Overall): 89% (24800/27632)\n",
      "Validation Accuracy (Overall): 88% (2089/2368)\n",
      "Epoch: 230 \tTraining Loss: 0.281563 \tValidation Loss: 0.530851\n",
      "Training Accuracy (Overall): 89% (24792/27632)\n",
      "Validation Accuracy (Overall): 84% (2000/2368)\n",
      "Epoch: 231 \tTraining Loss: 0.282000 \tValidation Loss: 0.413119\n",
      "Training Accuracy (Overall): 90% (24883/27632)\n",
      "Validation Accuracy (Overall): 86% (2058/2368)\n",
      "Epoch: 232 \tTraining Loss: 0.289157 \tValidation Loss: 0.706208\n",
      "Training Accuracy (Overall): 89% (24752/27632)\n",
      "Validation Accuracy (Overall): 81% (1929/2368)\n",
      "Epoch: 233 \tTraining Loss: 0.293391 \tValidation Loss: 0.651799\n",
      "Training Accuracy (Overall): 89% (24675/27632)\n",
      "Validation Accuracy (Overall): 82% (1958/2368)\n",
      "Epoch: 234 \tTraining Loss: 0.281418 \tValidation Loss: 0.903829\n",
      "Training Accuracy (Overall): 89% (24845/27632)\n",
      "Validation Accuracy (Overall): 77% (1825/2368)\n",
      "Epoch: 235 \tTraining Loss: 0.282632 \tValidation Loss: 0.389659\n",
      "Training Accuracy (Overall): 89% (24831/27632)\n",
      "Validation Accuracy (Overall): 87% (2068/2368)\n",
      "Epoch: 236 \tTraining Loss: 0.282521 \tValidation Loss: 0.425975\n",
      "Training Accuracy (Overall): 89% (24812/27632)\n",
      "Validation Accuracy (Overall): 87% (2071/2368)\n",
      "Epoch: 237 \tTraining Loss: 0.269078 \tValidation Loss: 0.474356\n",
      "Training Accuracy (Overall): 90% (24948/27632)\n",
      "Validation Accuracy (Overall): 85% (2014/2368)\n",
      "Epoch: 238 \tTraining Loss: 0.278300 \tValidation Loss: 0.458594\n",
      "Training Accuracy (Overall): 89% (24854/27632)\n",
      "Validation Accuracy (Overall): 86% (2043/2368)\n",
      "Epoch: 239 \tTraining Loss: 0.294598 \tValidation Loss: 0.406168\n",
      "Training Accuracy (Overall): 89% (24694/27632)\n",
      "Validation Accuracy (Overall): 87% (2067/2368)\n",
      "Epoch: 240 \tTraining Loss: 0.282053 \tValidation Loss: 0.400590\n",
      "Training Accuracy (Overall): 89% (24804/27632)\n",
      "Validation Accuracy (Overall): 87% (2083/2368)\n",
      "Epoch: 241 \tTraining Loss: 0.279941 \tValidation Loss: 0.388527\n",
      "Training Accuracy (Overall): 89% (24827/27632)\n",
      "Validation Accuracy (Overall): 88% (2094/2368)\n",
      "Epoch: 242 \tTraining Loss: 0.272935 \tValidation Loss: 0.549753\n",
      "Training Accuracy (Overall): 90% (24942/27632)\n",
      "Validation Accuracy (Overall): 84% (2005/2368)\n",
      "Epoch: 243 \tTraining Loss: 0.286078 \tValidation Loss: 0.570431\n",
      "Training Accuracy (Overall): 89% (24779/27632)\n",
      "Validation Accuracy (Overall): 84% (2005/2368)\n",
      "Epoch: 244 \tTraining Loss: 0.289092 \tValidation Loss: 0.459140\n",
      "Training Accuracy (Overall): 89% (24704/27632)\n",
      "Validation Accuracy (Overall): 85% (2025/2368)\n",
      "Epoch: 245 \tTraining Loss: 0.285628 \tValidation Loss: 0.418323\n",
      "Training Accuracy (Overall): 89% (24782/27632)\n",
      "Validation Accuracy (Overall): 86% (2051/2368)\n",
      "Epoch: 246 \tTraining Loss: 0.297914 \tValidation Loss: 0.802099\n",
      "Training Accuracy (Overall): 89% (24682/27632)\n",
      "Validation Accuracy (Overall): 80% (1900/2368)\n",
      "Epoch: 247 \tTraining Loss: 0.289165 \tValidation Loss: 0.507253\n",
      "Training Accuracy (Overall): 89% (24759/27632)\n",
      "Validation Accuracy (Overall): 85% (2017/2368)\n",
      "Epoch: 248 \tTraining Loss: 0.276461 \tValidation Loss: 0.455499\n",
      "Training Accuracy (Overall): 90% (24902/27632)\n",
      "Validation Accuracy (Overall): 87% (2079/2368)\n",
      "Epoch: 249 \tTraining Loss: 0.274759 \tValidation Loss: 0.405551\n",
      "Training Accuracy (Overall): 90% (24929/27632)\n",
      "Validation Accuracy (Overall): 87% (2075/2368)\n",
      "Epoch: 250 \tTraining Loss: 0.279636 \tValidation Loss: 0.616221\n",
      "Training Accuracy (Overall): 89% (24861/27632)\n",
      "Validation Accuracy (Overall): 82% (1955/2368)\n",
      "Epoch: 251 \tTraining Loss: 0.276675 \tValidation Loss: 0.508080\n",
      "Training Accuracy (Overall): 90% (24870/27632)\n",
      "Validation Accuracy (Overall): 84% (2006/2368)\n",
      "Epoch: 252 \tTraining Loss: 0.269296 \tValidation Loss: 0.426455\n",
      "Training Accuracy (Overall): 90% (24925/27632)\n",
      "Validation Accuracy (Overall): 87% (2066/2368)\n",
      "Epoch: 253 \tTraining Loss: 0.273189 \tValidation Loss: 0.429186\n",
      "Training Accuracy (Overall): 90% (24885/27632)\n",
      "Validation Accuracy (Overall): 86% (2047/2368)\n",
      "Epoch: 254 \tTraining Loss: 0.275927 \tValidation Loss: 0.516554\n",
      "Training Accuracy (Overall): 90% (24958/27632)\n",
      "Validation Accuracy (Overall): 84% (1999/2368)\n",
      "Epoch: 255 \tTraining Loss: 0.277251 \tValidation Loss: 0.420389\n",
      "Training Accuracy (Overall): 90% (24888/27632)\n",
      "Validation Accuracy (Overall): 86% (2053/2368)\n",
      "Epoch: 256 \tTraining Loss: 0.264073 \tValidation Loss: 0.373163\n",
      "Training Accuracy (Overall): 90% (25042/27632)\n",
      "Validation Accuracy (Overall): 88% (2104/2368)\n",
      "Epoch: 257 \tTraining Loss: 0.272724 \tValidation Loss: 0.434557\n",
      "Training Accuracy (Overall): 90% (24925/27632)\n",
      "Validation Accuracy (Overall): 87% (2073/2368)\n",
      "Epoch: 258 \tTraining Loss: 0.275341 \tValidation Loss: 0.604852\n",
      "Training Accuracy (Overall): 90% (24873/27632)\n",
      "Validation Accuracy (Overall): 83% (1969/2368)\n",
      "Epoch: 259 \tTraining Loss: 0.265504 \tValidation Loss: 0.431062\n",
      "Training Accuracy (Overall): 90% (25042/27632)\n",
      "Validation Accuracy (Overall): 87% (2064/2368)\n",
      "Epoch: 260 \tTraining Loss: 0.275358 \tValidation Loss: 0.563411\n",
      "Training Accuracy (Overall): 90% (24909/27632)\n",
      "Validation Accuracy (Overall): 84% (1990/2368)\n",
      "Epoch: 261 \tTraining Loss: 0.273369 \tValidation Loss: 0.789174\n",
      "Training Accuracy (Overall): 90% (24932/27632)\n",
      "Validation Accuracy (Overall): 79% (1879/2368)\n",
      "Epoch: 262 \tTraining Loss: 0.261658 \tValidation Loss: 0.477037\n",
      "Training Accuracy (Overall): 90% (25022/27632)\n",
      "Validation Accuracy (Overall): 85% (2025/2368)\n",
      "Epoch: 263 \tTraining Loss: 0.273805 \tValidation Loss: 0.553821\n",
      "Training Accuracy (Overall): 90% (24942/27632)\n",
      "Validation Accuracy (Overall): 84% (2000/2368)\n",
      "Epoch: 264 \tTraining Loss: 0.280883 \tValidation Loss: 0.414254\n",
      "Training Accuracy (Overall): 89% (24816/27632)\n",
      "Validation Accuracy (Overall): 86% (2051/2368)\n",
      "Epoch: 265 \tTraining Loss: 0.271279 \tValidation Loss: 0.594354\n",
      "Training Accuracy (Overall): 90% (24898/27632)\n",
      "Validation Accuracy (Overall): 83% (1971/2368)\n",
      "Epoch: 266 \tTraining Loss: 0.269337 \tValidation Loss: 0.436302\n",
      "Training Accuracy (Overall): 90% (24913/27632)\n",
      "Validation Accuracy (Overall): 87% (2063/2368)\n",
      "Epoch: 267 \tTraining Loss: 0.261625 \tValidation Loss: 0.514632\n",
      "Training Accuracy (Overall): 90% (25031/27632)\n",
      "Validation Accuracy (Overall): 86% (2055/2368)\n",
      "Epoch: 268 \tTraining Loss: 0.261968 \tValidation Loss: 0.386043\n",
      "Training Accuracy (Overall): 90% (25051/27632)\n",
      "Validation Accuracy (Overall): 87% (2083/2368)\n",
      "Epoch: 269 \tTraining Loss: 0.260419 \tValidation Loss: 0.430809\n",
      "Training Accuracy (Overall): 90% (24990/27632)\n",
      "Validation Accuracy (Overall): 87% (2065/2368)\n",
      "Epoch: 270 \tTraining Loss: 0.268540 \tValidation Loss: 0.427796\n",
      "Training Accuracy (Overall): 90% (24963/27632)\n",
      "Validation Accuracy (Overall): 87% (2068/2368)\n",
      "Epoch: 271 \tTraining Loss: 0.262707 \tValidation Loss: 0.539725\n",
      "Training Accuracy (Overall): 90% (25009/27632)\n",
      "Validation Accuracy (Overall): 84% (2000/2368)\n",
      "Epoch: 272 \tTraining Loss: 0.269396 \tValidation Loss: 0.479683\n",
      "Training Accuracy (Overall): 90% (24960/27632)\n",
      "Validation Accuracy (Overall): 86% (2055/2368)\n",
      "Epoch: 273 \tTraining Loss: 0.264403 \tValidation Loss: 0.430742\n",
      "Training Accuracy (Overall): 90% (24998/27632)\n",
      "Validation Accuracy (Overall): 88% (2091/2368)\n",
      "Epoch: 274 \tTraining Loss: 0.257622 \tValidation Loss: 0.402188\n",
      "Training Accuracy (Overall): 90% (25067/27632)\n",
      "Validation Accuracy (Overall): 87% (2070/2368)\n",
      "Epoch: 275 \tTraining Loss: 0.255220 \tValidation Loss: 0.594949\n",
      "Training Accuracy (Overall): 90% (25050/27632)\n",
      "Validation Accuracy (Overall): 83% (1983/2368)\n",
      "Epoch: 276 \tTraining Loss: 0.265598 \tValidation Loss: 0.437450\n",
      "Training Accuracy (Overall): 90% (24985/27632)\n",
      "Validation Accuracy (Overall): 87% (2073/2368)\n",
      "Epoch: 277 \tTraining Loss: 0.272339 \tValidation Loss: 0.451533\n",
      "Training Accuracy (Overall): 90% (24948/27632)\n",
      "Validation Accuracy (Overall): 86% (2051/2368)\n",
      "Epoch: 278 \tTraining Loss: 0.268578 \tValidation Loss: 0.435671\n",
      "Training Accuracy (Overall): 90% (24953/27632)\n",
      "Validation Accuracy (Overall): 86% (2059/2368)\n",
      "Epoch: 279 \tTraining Loss: 0.268286 \tValidation Loss: 0.457978\n",
      "Training Accuracy (Overall): 90% (24956/27632)\n",
      "Validation Accuracy (Overall): 86% (2044/2368)\n",
      "Epoch: 280 \tTraining Loss: 0.261075 \tValidation Loss: 0.524416\n",
      "Training Accuracy (Overall): 90% (25071/27632)\n",
      "Validation Accuracy (Overall): 84% (2002/2368)\n",
      "Epoch: 281 \tTraining Loss: 0.271085 \tValidation Loss: 0.433984\n",
      "Training Accuracy (Overall): 90% (24940/27632)\n",
      "Validation Accuracy (Overall): 87% (2080/2368)\n",
      "Epoch: 282 \tTraining Loss: 0.263790 \tValidation Loss: 0.477570\n",
      "Training Accuracy (Overall): 90% (24986/27632)\n",
      "Validation Accuracy (Overall): 85% (2028/2368)\n",
      "Epoch: 283 \tTraining Loss: 0.261175 \tValidation Loss: 0.447953\n",
      "Training Accuracy (Overall): 90% (25037/27632)\n",
      "Validation Accuracy (Overall): 86% (2040/2368)\n",
      "Epoch: 284 \tTraining Loss: 0.254526 \tValidation Loss: 0.519813\n",
      "Training Accuracy (Overall): 90% (25098/27632)\n",
      "Validation Accuracy (Overall): 85% (2023/2368)\n",
      "Epoch: 285 \tTraining Loss: 0.248922 \tValidation Loss: 0.536802\n",
      "Training Accuracy (Overall): 91% (25152/27632)\n",
      "Validation Accuracy (Overall): 85% (2018/2368)\n",
      "Epoch: 286 \tTraining Loss: 0.255594 \tValidation Loss: 0.460261\n",
      "Training Accuracy (Overall): 90% (25116/27632)\n",
      "Validation Accuracy (Overall): 86% (2060/2368)\n",
      "Epoch: 287 \tTraining Loss: 0.250315 \tValidation Loss: 0.409362\n",
      "Training Accuracy (Overall): 90% (25142/27632)\n",
      "Validation Accuracy (Overall): 88% (2090/2368)\n",
      "Epoch: 288 \tTraining Loss: 0.256268 \tValidation Loss: 0.419275\n",
      "Training Accuracy (Overall): 90% (25122/27632)\n",
      "Validation Accuracy (Overall): 87% (2082/2368)\n",
      "Epoch: 289 \tTraining Loss: 0.249643 \tValidation Loss: 0.498594\n",
      "Training Accuracy (Overall): 91% (25155/27632)\n",
      "Validation Accuracy (Overall): 86% (2051/2368)\n",
      "Epoch: 290 \tTraining Loss: 0.253089 \tValidation Loss: 0.400620\n",
      "Training Accuracy (Overall): 90% (25108/27632)\n",
      "Validation Accuracy (Overall): 88% (2084/2368)\n",
      "Epoch: 291 \tTraining Loss: 0.250247 \tValidation Loss: 0.377018\n",
      "Training Accuracy (Overall): 91% (25148/27632)\n",
      "Validation Accuracy (Overall): 88% (2093/2368)\n",
      "Epoch: 292 \tTraining Loss: 0.255865 \tValidation Loss: 0.485479\n",
      "Training Accuracy (Overall): 90% (25074/27632)\n",
      "Validation Accuracy (Overall): 85% (2028/2368)\n",
      "Epoch: 293 \tTraining Loss: 0.257211 \tValidation Loss: 0.448529\n",
      "Training Accuracy (Overall): 90% (25091/27632)\n",
      "Validation Accuracy (Overall): 87% (2066/2368)\n",
      "Epoch: 294 \tTraining Loss: 0.252520 \tValidation Loss: 0.408544\n",
      "Training Accuracy (Overall): 90% (25121/27632)\n",
      "Validation Accuracy (Overall): 87% (2081/2368)\n",
      "Epoch: 295 \tTraining Loss: 0.258229 \tValidation Loss: 0.435953\n",
      "Training Accuracy (Overall): 90% (25056/27632)\n",
      "Validation Accuracy (Overall): 87% (2061/2368)\n",
      "Epoch: 296 \tTraining Loss: 0.251044 \tValidation Loss: 0.482853\n",
      "Training Accuracy (Overall): 90% (25124/27632)\n",
      "Validation Accuracy (Overall): 86% (2038/2368)\n",
      "Epoch: 297 \tTraining Loss: 0.269211 \tValidation Loss: 0.430885\n",
      "Training Accuracy (Overall): 90% (24986/27632)\n",
      "Validation Accuracy (Overall): 86% (2057/2368)\n",
      "Epoch: 298 \tTraining Loss: 0.256079 \tValidation Loss: 0.452394\n",
      "Training Accuracy (Overall): 90% (25068/27632)\n",
      "Validation Accuracy (Overall): 86% (2056/2368)\n",
      "Epoch: 299 \tTraining Loss: 0.253129 \tValidation Loss: 0.378751\n",
      "Training Accuracy (Overall): 91% (25148/27632)\n",
      "Validation Accuracy (Overall): 88% (2094/2368)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SUBCLASS TRAINING\n",
    "\"\"\"\n",
    "from numpy.linalg import norm\n",
    "train_losslist = []\n",
    "train_losslist1 = []\n",
    "#number of epochs to train the model\n",
    "n_epochs = [*range(300)] # you may increase this number to train a final model\n",
    "\n",
    "valid_loss_min = np.Inf # track change in validation loss\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in n_epochs:\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    train_loss1 = 0.0\n",
    "    valid_loss = 0.0   \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "    #model1.train()\n",
    "    class_correct1 = list(0. for i in range(10))\n",
    "    class_total1 = list(0. for i in range(10))\n",
    "    for data, target in modelloader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        temp = list(target.size())\n",
    "        #print(list(target.size()))\n",
    "        newdata,newtarget,size = animaltransform(data,target,temp[0])\n",
    "        #lprint(newtarget)\n",
    "        newtarget = newtarget.type(torch.LongTensor) \n",
    "        newtarget = newtarget.to(device)\n",
    "       # print(newtarget.size())\n",
    "        #print(newtarget)\n",
    "        #print(newtarget)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        #optimizer1.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(newdata)\n",
    "        #output1 = model1(data)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, newtarget)\n",
    "        loss.backward()\n",
    "        \"\"\"\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \"\"\"\n",
    "\n",
    "        optimizer.step()\n",
    "        #optimizer1.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        #train_loss1 += loss1.item()*data.size(0)\n",
    "        _, pred = torch.max(output, 1)  \n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(newtarget.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(size):\n",
    "            label = newtarget.data[i]\n",
    "            class_correct1[label] += correct[i].item()\n",
    "            class_total1[label] += 1\n",
    "    ######################    \n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    for data, target in validloader:\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        #if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        newdata,newtarget,size = animaltransform(data,target,100)\n",
    "        newtarget = newtarget.type(torch.LongTensor) \n",
    "        newtarget = newtarget.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(newdata)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, newtarget)\n",
    "        # update average validation loss \n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output, 1)  \n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(newtarget.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "        # calculate test accuracy for each object class\n",
    "        for i in range(size):\n",
    "            label = newtarget.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "            # calculate average losses\n",
    "    valid_loss = valid_loss/len(validloader.dataset)\n",
    "    train_loss = train_loss/len(modelloader.dataset)\n",
    "    train_losslist.append(train_loss)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch, train_loss, valid_loss))\n",
    "    print('Training Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct1) / np.sum(class_total1),\n",
    "    np.sum(class_correct1), np.sum(class_total1)))\n",
    "    print('Validation Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95390fbf-0633-4cbe-9ce7-9272fb5dfbdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-10T19:26:53.207536Z",
     "iopub.status.busy": "2023-07-10T19:26:53.206515Z",
     "iopub.status.idle": "2023-07-10T19:26:53.262038Z",
     "shell.execute_reply": "2023-07-10T19:26:53.261013Z",
     "shell.execute_reply.started": "2023-07-10T19:26:53.207455Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"resnetdropout5000batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3eb7310-74ba-4a0d-bace-093521fe0d36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T04:25:42.379240Z",
     "iopub.status.busy": "2023-07-11T04:25:42.378876Z",
     "iopub.status.idle": "2023-07-11T04:25:44.154359Z",
     "shell.execute_reply": "2023-07-11T04:25:44.151857Z",
     "shell.execute_reply.started": "2023-07-11T04:25:42.379209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of airplane: 95% (3821/4000)\n",
      "Test Accuracy of automobile: 97% (5856/6000)\n",
      "Test Accuracy of  bird: N/A (no training examples)\n",
      "Test Accuracy of   cat: N/A (no training examples)\n",
      "Test Accuracy of  deer: N/A (no training examples)\n",
      "Test Accuracy of   dog: N/A (no training examples)\n",
      "Test Accuracy of  frog: N/A (no training examples)\n",
      "Test Accuracy of horse: N/A (no training examples)\n",
      "Test Accuracy of  ship: N/A (no training examples)\n",
      "Test Accuracy of truck: N/A (no training examples)\n",
      "\n",
      "Test Accuracy (Overall): 96% (9677/10000)\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "model.eval()\n",
    "for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        initialtarget = optimizedtransform(target,100)\n",
    "        initialtarget = initialtarget.type(torch.LongTensor) \n",
    "        initialtarget = initialtarget.to(device)\n",
    "        #print(initialtarget.size())\n",
    "      #  print(initialtarget)\n",
    "        output1 = model(data)\n",
    "        _, pred = torch.max(output1, 1) \n",
    "        correct_tensor = pred.eq(initialtarget.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "      #  print(correct)\n",
    "        \"\"\"\n",
    "        PRINT SAMPLES MISCATEGORIZED\n",
    "        DECREASE MODEL SIZE\n",
    "        TRAIN ANOTHER LAYER\n",
    "        OPTIMIZE BINARY CLASSIFIACTION DATASET\n",
    "        \"\"\"\n",
    "        for i in range(100):\n",
    "            label = initialtarget.data[i]\n",
    "          #  print(label)\n",
    "            class_correct[label] += correct[i]\n",
    "            class_total[label] += 1\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "               np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c0a03cf-ffa7-4372-8b5c-10b0522d5cc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T04:28:11.348872Z",
     "iopub.status.busy": "2023-07-11T04:28:11.348538Z",
     "iopub.status.idle": "2023-07-11T04:28:15.241879Z",
     "shell.execute_reply": "2023-07-11T04:28:15.240749Z",
     "shell.execute_reply.started": "2023-07-11T04:28:11.348846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.509587\n",
      "\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "[[85.7  1.6  6.8  2.9  2.6  0.4  0.   0.   0.   0. ]\n",
      " [ 2.4 75.4  3.3 14.8  3.6  0.5  0.   0.   0.   0. ]\n",
      " [ 0.9  1.6 94.8  1.2  0.5  1.   0.   0.   0.   0. ]\n",
      " [ 1.1  5.9  1.7 89.7  1.2  0.4  0.   0.   0.   0. ]\n",
      " [ 1.3  1.4  1.2  1.1 94.9  0.1  0.   0.   0.   0. ]\n",
      " [ 0.6  1.4  3.4  2.7  0.4 91.5  0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0.   0.   0.   0.   0.   0.   0. ]]\n",
      "Test Accuracy of airplane: 85% (857/1000)\n",
      "Test Accuracy of automobile: 75% (754/1000)\n",
      "Test Accuracy of  bird: 94% (948/1000)\n",
      "Test Accuracy of   cat: 89% (897/1000)\n",
      "Test Accuracy of  deer: 94% (949/1000)\n",
      "Test Accuracy of   dog: 91% (915/1000)\n",
      "Test Accuracy of  frog: N/A (no training examples)\n",
      "Test Accuracy of horse: N/A (no training examples)\n",
      "Test Accuracy of  ship: N/A (no training examples)\n",
      "Test Accuracy of truck: N/A (no training examples)\n",
      "\n",
      "Test Accuracy (Overall): 88% (5320/6000)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "matrix = np.zeros((10,10))\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "model.eval()\n",
    "# iterate over test data\n",
    "for data, target in testloader:\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    newdata,initialtarget,size = animaltransform(data,target,100)\n",
    "    initialtarget = initialtarget.type(torch.LongTensor) \n",
    "    initialtarget = initialtarget.to(device)\n",
    "        #print(initialtarget.size())\n",
    "      #  print(initialtarget)\n",
    "    output1 = model(newdata)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output1, initialtarget)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output1, 1)    \n",
    "    # compare predictions to true label\n",
    "  #  print(pred)\n",
    "    correct_tensor = pred.eq(initialtarget.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(size):\n",
    "        label = initialtarget.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "        matrix[label][pred[i]] +=1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(testloader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "matrix = matrix/10\n",
    "print(classes)\n",
    "print(matrix)\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c33beba4-25c4-4a4d-8ea1-fa22c7ca5330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T17:23:00.016592Z",
     "iopub.status.busy": "2023-07-11T17:23:00.016021Z",
     "iopub.status.idle": "2023-07-11T17:23:00.176055Z",
     "shell.execute_reply": "2023-07-11T17:23:00.175321Z",
     "shell.execute_reply.started": "2023-07-11T17:23:00.016553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): LambdaLayer()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): LambdaLayer()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = resnetlowest(2)\n",
    "animal = resnet20(6)\n",
    "vehicle = resnetlowest(2)\n",
    "cartruck = resnetlowest(2)\n",
    "airship = resnetlowest(2)\n",
    "model1.load_state_dict(torch.load(\"binarylowest\"))\n",
    "animal.load_state_dict(torch.load(\"animal5000batch\"))\n",
    "vehicle.load_state_dict(torch.load(\"vehiclelowesttree\"))\n",
    "cartruck.load_state_dict(torch.load(\"cartrucktree\"))\n",
    "airship.load_state_dict(torch.load(\"airshiptree\"))\n",
    "cartruck.to(device)\n",
    "airship.to(device)\n",
    "model1.to(device)\n",
    "animal.to(device)\n",
    "vehicle.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9b06a3b-3065-44ae-a420-aaf311622c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T04:33:23.084182Z",
     "iopub.status.busy": "2023-07-11T04:33:23.083505Z",
     "iopub.status.idle": "2023-07-11T04:34:21.862536Z",
     "shell.execute_reply": "2023-07-11T04:34:21.861637Z",
     "shell.execute_reply.started": "2023-07-11T04:33:23.084151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of airplane: 85% (855/1000)\n",
      "Test Accuracy of automobile: 87% (873/1000)\n",
      "Test Accuracy of  bird: 80% (808/1000)\n",
      "Test Accuracy of   cat: 73% (735/1000)\n",
      "Test Accuracy of  deer: 93% (937/1000)\n",
      "Test Accuracy of   dog: 88% (887/1000)\n",
      "Test Accuracy of  frog: 94% (942/1000)\n",
      "Test Accuracy of horse: 89% (895/1000)\n",
      "Test Accuracy of  ship: 92% (921/1000)\n",
      "Test Accuracy of truck: 89% (894/1000)\n",
      "\n",
      "Test Accuracy (Overall): 87% (8747/10000)\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "matrix = np.zeros((10,10))\n",
    "model1.eval()\n",
    "animal.eval()\n",
    "vehicle.eval()\n",
    "cartruck.eval()\n",
    "airship.eval()\n",
    "for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output1 = model1(data)\n",
    "        _, pred = torch.max(output1, 1) \n",
    "        if pred == 0:\n",
    "            output2 = vehicle(data)\n",
    "            _, pred2 = torch.max(output2, 1)\n",
    "            if pred2 == 0:\n",
    "                output3 = airship(data)\n",
    "                _, pred3 = torch.max(output3, 1)\n",
    "               # print(pred3)\n",
    "                predfinal = pred3\n",
    "                if pred3[0] != 0:\n",
    "                    predfinal = pred3 + 7\n",
    "            if pred2 == 1:\n",
    "                output3 = cartruck(data)\n",
    "                _, pred3 = torch.max(output3, 1)\n",
    "                predfinal = pred3\n",
    "              #  print(pred3)\n",
    "               # print(target)\n",
    "                if pred3 == 0:\n",
    "                    predfinal =predfinal + 1\n",
    "                else:                    \n",
    "                    predfinal =predfinal + 8   \n",
    "        if pred == 1:\n",
    "            output2 = animal(data)\n",
    "            _, pred2 = torch.max(output2, 1)\n",
    "            predfinal = pred2 +2\n",
    "        correct_tensor = predfinal.eq(target.data.view_as(predfinal))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "        label = target.data[0]\n",
    "        class_correct[label] += correct.item()\n",
    "        class_total[label] += 1\n",
    "        matrix[label][predfinal] +=1\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9e78bf-e5e4-4868-a158-85a3d6112759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T04:30:16.652893Z",
     "iopub.status.busy": "2023-07-11T04:30:16.652185Z",
     "iopub.status.idle": "2023-07-11T04:31:15.378304Z",
     "shell.execute_reply": "2023-07-11T04:31:15.377089Z",
     "shell.execute_reply.started": "2023-07-11T04:30:16.652861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of airplane: 87% (876/1000)\n",
      "Test Accuracy of automobile: 90% (904/1000)\n",
      "Test Accuracy of  bird: 80% (808/1000)\n",
      "Test Accuracy of   cat: 73% (735/1000)\n",
      "Test Accuracy of  deer: 93% (937/1000)\n",
      "Test Accuracy of   dog: 88% (887/1000)\n",
      "Test Accuracy of  frog: 94% (942/1000)\n",
      "Test Accuracy of horse: 89% (895/1000)\n",
      "Test Accuracy of  ship: 91% (918/1000)\n",
      "Test Accuracy of truck: 95% (952/1000)\n",
      "\n",
      "Test Accuracy (Overall): 88% (8854/10000)\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "model1.eval()\n",
    "animal.eval()\n",
    "vehicle.eval()\n",
    "for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output1 = model1(data)\n",
    "        _, pred = torch.max(output1, 1) \n",
    "        if pred == 0:\n",
    "            output2 = vehicle(data)\n",
    "            _, pred2 = torch.max(output2, 1)\n",
    "            predfinal = pred2\n",
    "            if predfinal > 1:\n",
    "                predfinal = predfinal + 6\n",
    "        if pred == 1:\n",
    "            output2 = animal(data)\n",
    "            _, pred2 = torch.max(output2, 1)\n",
    "            predfinal = pred2 + 2\n",
    "        correct_tensor = predfinal.eq(target.data.view_as(predfinal))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "        label = target.data[0]\n",
    "        class_correct[label] += correct.item()\n",
    "        class_total[label] += 1\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a633ea2d-f6c0-4633-b144-3efc4017daa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-11T17:23:37.904619Z",
     "iopub.status.busy": "2023-07-11T17:23:37.904270Z",
     "iopub.status.idle": "2023-07-11T17:24:12.310577Z",
     "shell.execute_reply": "2023-07-11T17:24:12.309532Z",
     "shell.execute_reply.started": "2023-07-11T17:23:37.904589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of airplane: 93% (938/1000)\n",
      "Test Accuracy of automobile: 89% (895/1000)\n",
      "Test Accuracy of  bird: N/A (no training examples)\n",
      "Test Accuracy of   cat: N/A (no training examples)\n",
      "Test Accuracy of  deer: N/A (no training examples)\n",
      "Test Accuracy of   dog: N/A (no training examples)\n",
      "Test Accuracy of  frog: N/A (no training examples)\n",
      "Test Accuracy of horse: N/A (no training examples)\n",
      "Test Accuracy of  ship: 94% (948/1000)\n",
      "Test Accuracy of truck: 90% (909/1000)\n",
      "\n",
      "Test Accuracy (Overall): 92% (3690/4000)\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "matrix = np.zeros((10,10))\n",
    "vehicle.eval()\n",
    "cartruck.eval()\n",
    "airship.eval()\n",
    "for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        if target <= 1 or target > 7:\n",
    "            output2 = vehicle(data)\n",
    "            _, pred2 = torch.max(output2, 1)\n",
    "            if pred2 == 0:\n",
    "                output3 = airship(data)\n",
    "                _, pred3 = torch.max(output3, 1)\n",
    "               # print(pred3)\n",
    "                predfinal = pred3\n",
    "                if pred3[0] != 0:\n",
    "                    predfinal = pred3 + 7\n",
    "            if pred2 == 1:\n",
    "                output3 = cartruck(data)\n",
    "                _, pred3 = torch.max(output3, 1)\n",
    "                predfinal = pred3\n",
    "              #  print(pred3)\n",
    "               # print(target)\n",
    "                if pred3 == 0:\n",
    "                    predfinal =predfinal + 1\n",
    "                else:                    \n",
    "                    predfinal =predfinal + 8   \n",
    "            correct_tensor = predfinal.eq(target.data.view_as(predfinal))\n",
    "            correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "            label = target.data[0]\n",
    "            class_correct[label] += correct.item()\n",
    "            class_total[label] += 1\n",
    "            matrix[label][predfinal] +=1\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
