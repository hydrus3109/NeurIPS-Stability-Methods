{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hydrus3109/PRIMES_AIprivacy/blob/main/Pair_wise_stability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libraries"
      ],
      "metadata": {
        "id": "l5AtrtJMBqqj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3J1luxsGiVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803bba90-f1a5-465b-c6d5-69c7867c46fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opacus in /usr/local/lib/python3.9/dist-packages (1.3.0)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.9/dist-packages (from opacus) (2.0.0)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from opacus) (3.3.0)\n",
            "Requirement already satisfied: functorch in /usr/local/lib/python3.9/dist-packages (from opacus) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.9/dist-packages (from opacus) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.9/dist-packages (from opacus) (1.10.1)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.4.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (3.9.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.7.4.91)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (4.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (2.14.3)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (2.0.0)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.7.91)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.7.101)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (1.7.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8->opacus) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8->opacus) (63.4.3)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8->opacus) (15.0.7)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8->opacus) (3.22.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8->opacus) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8->opacus) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: e2cnn in /usr/local/lib/python3.9/dist-packages (0.2.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from e2cnn) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from e2cnn) (1.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from e2cnn) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from e2cnn) (1.10.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->e2cnn) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (11.10.3.66)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (2.14.3)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (2.0.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (8.5.0.96)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (3.9.0)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (11.7.99)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (11.7.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (11.7.99)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->e2cnn) (3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->e2cnn) (63.4.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->e2cnn) (0.38.4)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->e2cnn) (3.22.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->e2cnn) (15.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->e2cnn) (2.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opacus in /usr/local/lib/python3.9/dist-packages (1.3.0)\n",
            "Requirement already satisfied: functorch in /usr/local/lib/python3.9/dist-packages (from opacus) (2.0.0)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from opacus) (3.3.0)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.9/dist-packages (from opacus) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.9/dist-packages (from opacus) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.9/dist-packages (from opacus) (1.10.1)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.7.4.91)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (4.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (2.14.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (3.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (1.7.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.7.99)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.7.101)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.7.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (11.4.0.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (3.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8->opacus) (8.5.0.96)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8->opacus) (63.4.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8->opacus) (0.38.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8->opacus) (15.0.7)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8->opacus) (3.22.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8->opacus) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8->opacus) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opacus\n",
        "!pip install e2cnn\n",
        "from e2cnn import gspaces\n",
        "from e2cnn import nn\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "!pip install opacus\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import RandomRotation\n",
        "from torchvision.transforms import Pad\n",
        "from torchvision.transforms import Resize\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Compose\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model\n",
        "\n"
      ],
      "metadata": {
        "id": "Ty2hdfzYB4zA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.random import device_count\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import RandomRotation\n",
        "from torchvision.transforms import Pad\n",
        "from torchvision.transforms import Resize\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Compose\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset =CIFAR10(root='./', train=True,download=True,transform = transform)\n",
        "train = list(range(10, 1000,1))\n",
        "valid = list(range(1000, 2000,1))\n",
        "test = list(range(0,1000,1))\n",
        "\n",
        "trainset_1 = torch.utils.data.Subset(trainset, train)\n",
        "trainloader_1 = torch.utils.data.DataLoader(trainset_1, shuffle=True, num_workers=4,batch_size = 20)\n",
        "validset = torch.utils.data.Subset(trainset, valid)\n",
        "validloader = torch.utils.data.DataLoader(validset, shuffle=True, num_workers=4,batch_size = 20)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train = False, download=True, transform=transform)\n",
        "testset_1 = torch.utils.data.Subset(testset, train)\n",
        "testloader_1 = torch.utils.data.DataLoader(testset_1, shuffle=True, num_workers=4,batch_size = 20)\n",
        "print(len(trainset_1))\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "39n8C1tRgNVK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "5b8151ec-9e45-483b-e08e-aeaa8f618fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5ba92e537d60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     58\u001b[0m     ) -> None:\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m  \u001b[0;31m# training set or test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/vision.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transforms, transform, target_transform)\u001b[0m\n\u001b[1;32m     37\u001b[0m     ) -> None:\n\u001b[1;32m     38\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute '_six'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "# helper function to un-normalize and display an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
        "# obtain one batch of training images\n",
        "dataiter = iter(trainloader_1)\n",
        "images, labels = next(dataiter)\n",
        "images = images.numpy() # convert images to numpy for display\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "# display 20 images\n",
        "for idx in np.arange(20):\n",
        "  ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
        "  imshow(images[idx])\n",
        "  ax.set_title(classes[labels[idx]])"
      ],
      "metadata": {
        "id": "9nOGZklGvsXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "I-undE_fyaMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "metadata": {
        "id": "if60536s93-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class CNN(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.GroupNorm(4,32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.GroupNorm(4,128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.GroupNorm(4,256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "\n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "\n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x\n",
        "model = CNN()\n",
        "print(model)\n",
        "#print(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# specify optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji4uubLlybDn",
        "outputId": "48356e55-ee18-4442-891b-689c0003a87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05, inplace=False)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1, inplace=False)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.1, inplace=False)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 1:"
      ],
      "metadata": {
        "id": "5WsfXfKjzWUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losslist = []\n",
        "# number of epochs to train the model\n",
        "n_epochs = [*range(30)] # you may increase this number to train a final model\n",
        "\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "for epoch in n_epochs:\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data, target in trainloader_1:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "       # if train_on_gpu:\n",
        "           # data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "    ######################\n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in validloader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        #if train_on_gpu:\n",
        "            #data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "\n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(trainloader_1.dataset)\n",
        "    valid_loss = valid_loss/len(validloader.dataset)\n",
        "\n",
        "    train_losslist.append(train_loss)\n",
        "\n",
        "    # print training/validation statistics\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "\n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTN9CEJ35H_B",
        "outputId": "1ca018ce-83d3-4f8e-9e0a-8db79b58a050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 \tTraining Loss: 2.301538 \tValidation Loss: 2.299052\n",
            "Validation loss decreased (inf --> 2.299052).  Saving model ...\n",
            "Epoch: 1 \tTraining Loss: 2.296779 \tValidation Loss: 2.294651\n",
            "Validation loss decreased (2.299052 --> 2.294651).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 2.292773 \tValidation Loss: 2.290282\n",
            "Validation loss decreased (2.294651 --> 2.290282).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 2.287542 \tValidation Loss: 2.285661\n",
            "Validation loss decreased (2.290282 --> 2.285661).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 2.282698 \tValidation Loss: 2.280748\n",
            "Validation loss decreased (2.285661 --> 2.280748).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 2.276447 \tValidation Loss: 2.274786\n",
            "Validation loss decreased (2.280748 --> 2.274786).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 2.269247 \tValidation Loss: 2.267651\n",
            "Validation loss decreased (2.274786 --> 2.267651).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 2.261552 \tValidation Loss: 2.259769\n",
            "Validation loss decreased (2.267651 --> 2.259769).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 2.252753 \tValidation Loss: 2.249592\n",
            "Validation loss decreased (2.259769 --> 2.249592).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 2.243013 \tValidation Loss: 2.237598\n",
            "Validation loss decreased (2.249592 --> 2.237598).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 2.230667 \tValidation Loss: 2.223831\n",
            "Validation loss decreased (2.237598 --> 2.223831).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 2.214046 \tValidation Loss: 2.208289\n",
            "Validation loss decreased (2.223831 --> 2.208289).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 2.195783 \tValidation Loss: 2.188328\n",
            "Validation loss decreased (2.208289 --> 2.188328).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 2.174369 \tValidation Loss: 2.166179\n",
            "Validation loss decreased (2.188328 --> 2.166179).  Saving model ...\n",
            "Epoch: 14 \tTraining Loss: 2.147665 \tValidation Loss: 2.139088\n",
            "Validation loss decreased (2.166179 --> 2.139088).  Saving model ...\n",
            "Epoch: 15 \tTraining Loss: 2.115321 \tValidation Loss: 2.106750\n",
            "Validation loss decreased (2.139088 --> 2.106750).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 2.077174 \tValidation Loss: 2.070018\n",
            "Validation loss decreased (2.106750 --> 2.070018).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 2.040554 \tValidation Loss: 2.036018\n",
            "Validation loss decreased (2.070018 --> 2.036018).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 2.003032 \tValidation Loss: 2.000234\n",
            "Validation loss decreased (2.036018 --> 2.000234).  Saving model ...\n",
            "Epoch: 19 \tTraining Loss: 1.960024 \tValidation Loss: 1.968289\n",
            "Validation loss decreased (2.000234 --> 1.968289).  Saving model ...\n",
            "Epoch: 20 \tTraining Loss: 1.927252 \tValidation Loss: 1.932383\n",
            "Validation loss decreased (1.968289 --> 1.932383).  Saving model ...\n",
            "Epoch: 21 \tTraining Loss: 1.891002 \tValidation Loss: 1.900703\n",
            "Validation loss decreased (1.932383 --> 1.900703).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 1.872057 \tValidation Loss: 1.874640\n",
            "Validation loss decreased (1.900703 --> 1.874640).  Saving model ...\n",
            "Epoch: 23 \tTraining Loss: 1.826604 \tValidation Loss: 1.843852\n",
            "Validation loss decreased (1.874640 --> 1.843852).  Saving model ...\n",
            "Epoch: 24 \tTraining Loss: 1.798099 \tValidation Loss: 1.827463\n",
            "Validation loss decreased (1.843852 --> 1.827463).  Saving model ...\n",
            "Epoch: 25 \tTraining Loss: 1.773581 \tValidation Loss: 1.797744\n",
            "Validation loss decreased (1.827463 --> 1.797744).  Saving model ...\n",
            "Epoch: 26 \tTraining Loss: 1.756167 \tValidation Loss: 1.773263\n",
            "Validation loss decreased (1.797744 --> 1.773263).  Saving model ...\n",
            "Epoch: 27 \tTraining Loss: 1.729739 \tValidation Loss: 1.772984\n",
            "Validation loss decreased (1.773263 --> 1.772984).  Saving model ...\n",
            "Epoch: 28 \tTraining Loss: 1.697199 \tValidation Loss: 1.737005\n",
            "Validation loss decreased (1.772984 --> 1.737005).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 1.672615 \tValidation Loss: 1.729720\n",
            "Validation loss decreased (1.737005 --> 1.729720).  Saving model ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "# iterate over test data\n",
        "for data, target in testloader_1:\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    #data, target = data.cuda(), target.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the batch loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss\n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(20):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(testloader_1.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "metadata": {
        "id": "0Aj07AKE9guh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6be3fbf-f1b5-443d-8c4c-3b2345ed69ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.713490\n",
            "\n",
            "Test Accuracy of airplane: 57% (101/176)\n",
            "Test Accuracy of automobile: 51% (94/184)\n",
            "Test Accuracy of  bird: 23% (41/174)\n",
            "Test Accuracy of   cat:  1% ( 2/180)\n",
            "Test Accuracy of  deer: 36% (66/183)\n",
            "Test Accuracy of   dog: 12% (21/167)\n",
            "Test Accuracy of  frog: 48% (93/190)\n",
            "Test Accuracy of horse: 44% (78/175)\n",
            "Test Accuracy of  ship: 47% (90/189)\n",
            "Test Accuracy of truck: 43% (79/182)\n",
            "\n",
            "Test Accuracy (Overall): 36% (665/1800)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 2"
      ],
      "metadata": {
        "id": "2fN-6uUtzaY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "comparison and saving"
      ],
      "metadata": {
        "id": "ojuzRVc3NQ4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "params1 = []\n",
        "norms1 = []\n",
        "for param in m.parameters():\n",
        "   # print(param)\n",
        "    temp = param.detach().numpy()\n",
        "    norms1.append(norm(temp))\n",
        "    print(np.shape(temp))\n",
        "    params1.append(temp)\n",
        "print(np.shape(params1))\n",
        "print(norm(norms1))\n",
        ""
      ],
      "metadata": {
        "id": "HffejSAINQmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf22bd8-a5af-4f36-b977-009f1b35cac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 3, 3, 3)\n",
            "(32,)\n",
            "(32,)\n",
            "(32,)\n",
            "(64, 32, 3, 3)\n",
            "(64,)\n",
            "(128, 64, 3, 3)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128, 128, 3, 3)\n",
            "(128,)\n",
            "(256, 128, 3, 3)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256, 256, 3, 3)\n",
            "(256,)\n",
            "(1024, 4096)\n",
            "(1024,)\n",
            "(512, 1024)\n",
            "(512,)\n",
            "(10, 512)\n",
            "(10,)\n",
            "(24,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "given an arbitrary data point removed, how much does output change"
      ],
      "metadata": {
        "id": "dKJNLhWpfzQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outfile1 = TemporaryFile()\n",
        "from numpy.linalg import norm\n",
        "params2 = []\n",
        "for param in model.parameters():\n",
        "   # print(param)\n",
        "    temp = param.detach().numpy()\n",
        "    print(np.shape(temp))\n",
        "    params2.append(temp)\n",
        "print(np.shape(params2))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-IBH0L6gKlg",
        "outputId": "483c7d2f-4bd5-4f4a-c398-a61c3a26ee78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 3, 3, 3)\n",
            "(32,)\n",
            "(32,)\n",
            "(32,)\n",
            "(64, 32, 3, 3)\n",
            "(64,)\n",
            "(128, 64, 3, 3)\n",
            "(128,)\n",
            "(128,)\n",
            "(128,)\n",
            "(128, 128, 3, 3)\n",
            "(128,)\n",
            "(256, 128, 3, 3)\n",
            "(256,)\n",
            "(256,)\n",
            "(256,)\n",
            "(256, 256, 3, 3)\n",
            "(256,)\n",
            "(1024, 4096)\n",
            "(1024,)\n",
            "(512, 1024)\n",
            "(512,)\n",
            "(10, 512)\n",
            "(10,)\n",
            "(24,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import linalg as LA\n",
        "results = []\n",
        "for x in range(24):\n",
        "  temp = params1[x]-params2[x]\n",
        "  results.append(LA.norm(temp))\n",
        "\n",
        "print(LA.norm(results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8eUXpmLhlNE",
        "outputId": "7f06ad30-af4b-4946-ec3d-e6e651e3ef96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40.390415\n"
          ]
        }
      ]
    }
  ]
}